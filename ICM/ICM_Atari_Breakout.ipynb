{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5147,
     "status": "ok",
     "timestamp": 1584644785363,
     "user": {
      "displayName": "Harry Songhurst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GieNgr7BK-9yyJpoq8YsIhNOD7Lykw7Jg6-uFso=s64",
      "userId": "17177898107918428203"
     },
     "user_tz": 0
    },
    "id": "MiWy-wSlg65h",
    "outputId": "1249347c-fddf-4fef-bea7-f3777845e1b8"
   },
   "outputs": [],
   "source": [
    "!pip install stable-baselines==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16448,
     "status": "ok",
     "timestamp": 1584644796690,
     "user": {
      "displayName": "Harry Songhurst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GieNgr7BK-9yyJpoq8YsIhNOD7Lykw7Jg6-uFso=s64",
      "userId": "17177898107918428203"
     },
     "user_tz": 0
    },
    "id": "dZmBmHSCwNRk",
    "outputId": "39f75bde-39c4-4f86-c514-a3252d7d5a5f"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from time import time\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch as T\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from stable_baselines.common.misc_util import set_global_seeds\n",
    "from stable_baselines.common.cmd_util import make_atari_env\n",
    "from stable_baselines.common.vec_env import VecFrameStack, VecNormalize\n",
    "from stable_baselines.common.running_mean_std import RunningMeanStd\n",
    "\n",
    "from tqdm import trange\n",
    "from google.colab import drive\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44538,
     "status": "ok",
     "timestamp": 1584644824783,
     "user": {
      "displayName": "Harry Songhurst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GieNgr7BK-9yyJpoq8YsIhNOD7Lykw7Jg6-uFso=s64",
      "userId": "17177898107918428203"
     },
     "user_tz": 0
    },
    "id": "yl0qbkBdxITN",
    "outputId": "b6c66918-7580-4b63-8790-9a9e3bde740b"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ovKc19B7wQSv"
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'BreakoutNoFrameskip-v4'\n",
    "SAVE_PATH = '/content/gdrive/My Drive/ICM/'\n",
    "\n",
    "TOTAL_FRAMES = 5e6   # 10 million frames\n",
    "ROLLOUT_LENGTH = 128  # transitions in each rollout\n",
    "NENV = 8            # parallel environments, increase to decorrolate batches\n",
    "GAMMA = 0.99        # reward discounting coefficient\n",
    "LAMBDA = 0.95       # for GAE\n",
    "SEED = 420          # blaze it\n",
    "STEPS_PER_ROLLOUT = ROLLOUT_LENGTH*NENV\n",
    "TOTAL_UPDATES = int(TOTAL_FRAMES // STEPS_PER_ROLLOUT)\n",
    "DEVICE = T.device('cuda' if T.cuda.is_available() else 'cpu')\n",
    "\n",
    "set_global_seeds(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KqNCB_d6xifa"
   },
   "source": [
    "# Neural Net Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rbcEmU2k7kEA"
   },
   "outputs": [],
   "source": [
    "def conv_size(net, in_shape):\n",
    "    \"\"\" util for calculating flat output shape of a given net \"\"\"\n",
    "    x = Variable(T.rand(1, *in_shape))\n",
    "    o = net(x)\n",
    "    b = (-1, o.size(1), o.size(2), o.size(3))\n",
    "    return b, o.data.view(1, -1).size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Llngacnxifl"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'bias' in name:\n",
    "            nn.init.constant_(param, 0.01)\n",
    "        elif 'weight' in name:\n",
    "            nn.init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wcl3g06pf2Ml"
   },
   "outputs": [],
   "source": [
    "class AC(nn.Module):\n",
    "  \n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super().__init__()\n",
    "        h, w, c = input_shape\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(c, 32, 8, 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, 3, 1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        _,f = conv_size(self.conv, (c,h,w))\n",
    "        \n",
    "        self.backbone = nn.Sequential(self.conv, nn.Flatten())\n",
    "        self.actor = nn.Linear(f, num_actions)\n",
    "        self.critic = nn.Linear(f, 1)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.backbone(x)\n",
    "        return self.actor(latent), self.critic(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPpQqlPJ7iJZ"
   },
   "outputs": [],
   "source": [
    "class ICM(nn.Module):\n",
    "    \"\"\" ICM sources its intrinsic bonus from the ability of a predictor\n",
    "        network to estimate the action that was taken by the policy,\n",
    "        given as input two latent encodings (phi) of two adjacent states\n",
    "        (phi(S_t), phi(S_t+1)).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, num_actions, latent_size):\n",
    "        super().__init__()\n",
    "        h, w, c = input_shape\n",
    "        self.latent_size = latent_size\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        # 'features' from the paper diagram\n",
    "        # transform state into phi/latent representation\n",
    "        self.encoder_conv = nn.Sequential(\n",
    "            nn.Conv2d(c, 32, 8, 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 4, 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, 3, 1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.encoder_linear = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_size(self.encoder_conv, (c,h,w))[1], 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, self.latent_size)\n",
    "        )\n",
    "        self.encoder = nn.Sequential(\n",
    "            self.encoder_conv, \n",
    "            self.encoder_linear\n",
    "        )\n",
    "        \n",
    "        # predict encoder(S_t+1) from encoder(S_t + A_t)\n",
    "        self.forward_model = nn.Sequential(\n",
    "            nn.Linear(self.latent_size + self.num_actions, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self.latent_size)\n",
    "        )\n",
    "\n",
    "        # predict A_t from (S_t+1, S_t)\n",
    "        self.inverse_model = nn.Sequential(\n",
    "            nn.Linear(self.latent_size * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, self.num_actions)\n",
    "        )\n",
    "\n",
    "    def one_hot_actions(self, actions):\n",
    "        # actions are vector b/c env is VecEnv\n",
    "        z = T.zeros((len(actions), self.num_actions)).float().to(DEVICE)\n",
    "        for i in range(len(actions)):\n",
    "            z[i,actions[i]] = 1.0\n",
    "        return z\n",
    "\n",
    "    def forward(self, state, next_state, actions):\n",
    "        \"\"\" returns (inverse loss, forward loss/intrinsic bonus) \"\"\"\n",
    "        # encode states into latent space\n",
    "        phi_state = self.encoder(state)\n",
    "        phi_next_state = self.encoder(next_state)\n",
    "        # predict phi(S_t+1) given S_t and A_t\n",
    "        a = self.one_hot_actions(actions)\n",
    "\n",
    "        fwd_phi_act = T.cat([phi_state, a], dim=1)\n",
    "        phi_next_state_pred = self.forward_model(fwd_phi_act)\n",
    "        # predict the actions taken to get from S_t to S_t+1\n",
    "        rev = T.cat([phi_state, phi_next_state], 1)\n",
    "        actions_pred = self.inverse_model(rev)\n",
    "\n",
    "        # backprop to inverse model and encoder\n",
    "        inverse_loss = F.cross_entropy(actions_pred, actions)\n",
    "        # backprop to forward model and encoder\n",
    "        forward_loss = F.mse_loss(phi_next_state, \n",
    "                                  phi_next_state_pred.detach(), \n",
    "                                  reduce=False).sum(-1)\n",
    "\n",
    "        return inverse_loss, forward_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "996HBNYUxif5"
   },
   "source": [
    "# Logging utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eXGBboSkFQ9u"
   },
   "outputs": [],
   "source": [
    "class Logger:\n",
    "\n",
    "    def __init__(self, print_rate=250):\n",
    "        self.log = {'ep_r':[], 'ep_l':[], 'loss':[], 'pgloss':[], \n",
    "                    'vloss':[], 'ent':[], 'int':[], 'icm':[]}\n",
    "        self.n_ep = 0              # total games/episodes\n",
    "        self.n_update = 1          # total weight updates\n",
    "        self.n_frames = 0          # env steps (total from checkpoint)\n",
    "        self.run_frames = 0        # env steps (for this run)\n",
    "        self.max_rwd = -np.inf     # max rwd out of all games played\n",
    "        self.start_time = time()   # time we started *this* run\n",
    "        self.last_checkpoint = 0   # total_frames at last checkpoint\n",
    "        self.print_rate = print_rate\n",
    "\n",
    "    def eta(self):  # get hh:mm:ss left to train\n",
    "        elapsed_time = time() - self.start_time\n",
    "        frames_left = TOTAL_FRAMES - self.n_frames\n",
    "        sec_per_frame = elapsed_time / self.n_frames\n",
    "        sec_left = int(frames_left * sec_per_frame)\n",
    "        eta_str = str(datetime.timedelta(seconds=sec_left))\n",
    "        return eta_str\n",
    "\n",
    "    def fps(self):  # get frames per second\n",
    "        elapsed_time = time() - self.start_time\n",
    "        fps = int(self.run_frames / elapsed_time)\n",
    "        return fps\n",
    "\n",
    "    def sma(self, x):  # simple moving average\n",
    "        if len(x) == 0: return 'NaN'\n",
    "        div = 200 if len(x) > 200 else len(x)\n",
    "        return sum(list(zip(*x[-div:]))[-1])/div\n",
    "\n",
    "    def print_log(self):\n",
    "        fps = self.fps()\n",
    "        eta = self.eta()\n",
    "        print('-'*10, self.n_update, '/', TOTAL_UPDATES, '-'*10)\n",
    "        print('Num Games:', self.n_ep)\n",
    "        print('Num Frames:', self.n_frames)\n",
    "        print('FPS:', fps)\n",
    "        print('ETA:', eta)\n",
    "        print('SMA Length:', self.sma(self.log['ep_l']))\n",
    "        print('SMA Reward:', self.sma(self.log['ep_r']))\n",
    "        print('SMA Entropy:', self.sma(self.log['ent']))\n",
    "        print('SMA Loss:', self.sma(self.log['loss']))\n",
    "        print('SMA PG Loss:', self.sma(self.log['pgloss']))\n",
    "        print('SMA V Loss:', self.sma(self.log['vloss']))\n",
    "        print('SMA Intrinsic Reward:', self.sma(self.log['int']))\n",
    "        print('SMA ICM Loss:', self.sma(self.log['icm']))\n",
    "        print('Max reward:', self.max_rwd)\n",
    "\n",
    "    def record(self, ep, loss, pgloss, vloss, ent, intr, icm):\n",
    "        \n",
    "        self.n_update += 1\n",
    "        self.n_frames += STEPS_PER_ROLLOUT\n",
    "        self.run_frames += STEPS_PER_ROLLOUT\n",
    "        fr = (self.n_frames, self.n_update)\n",
    "\n",
    "        # stats about finished episodes/games\n",
    "        for l, r in zip(ep['l'], ep['r']):\n",
    "            self.log['ep_l'].append(fr+(l,))\n",
    "            self.log['ep_r'].append(fr+(r,))\n",
    "            if r > self.max_rwd: self.max_rwd = r\n",
    "            self.n_ep += 1\n",
    "             \n",
    "        # nn training statistics\n",
    "        self.log['loss'].append(fr+(loss,))\n",
    "        self.log['pgloss'].append(fr+(pgloss,))\n",
    "        self.log['vloss'].append(fr+(vloss,))\n",
    "        self.log['ent'].append(fr+(ent,))\n",
    "        self.log['int'].append(fr+(intr,))\n",
    "        self.log['icm'].append(fr+(icm,))\n",
    "        \n",
    "        # print log\n",
    "        if self.n_update % self.print_rate == 0:\n",
    "            self.print_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8BrJDF7YxigC"
   },
   "source": [
    "# Rollout handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TvvmxhV1xigD"
   },
   "outputs": [],
   "source": [
    "def ob_to_torch(x):\n",
    "    x = np.moveaxis(x, -1, 1)\n",
    "    x = T.from_numpy(x).float()\n",
    "    x = x.to(DEVICE)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVlCxZg3xigK"
   },
   "outputs": [],
   "source": [
    "def GAE(rwds, vals, next_val, dones=None):\n",
    "    \"\"\" GAE lambda. vals is full batch, next_val is singular \"\"\"\n",
    "    returns = T.empty_like(rwds).to(DEVICE)\n",
    "    if dones is None: dones = T.ones_like(rwds, dtype=T.bool)\n",
    "    g = 0\n",
    "    for i in reversed(range(ROLLOUT_LENGTH)):\n",
    "        d = rwds[i] + (GAMMA * next_val * ~dones[i]) - vals[i]\n",
    "        g = d + (GAMMA * LAMBDA * ~dones[i] * g)\n",
    "        returns[i] = g + vals[i]\n",
    "        next_val = vals[i]\n",
    "    adv = returns - vals\n",
    "    return returns, adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8EEfiG09KHcX"
   },
   "outputs": [],
   "source": [
    "def rollout_generator(env, policy):\n",
    "\n",
    "    ob = ob_to_torch(env.reset())\n",
    "    mb = {'obs':[], 'nobs':[], 'act':[], 'rwd':[], 'done':[], 'val':[]}\n",
    "    ep = {'l':[], 'r':[]}  # len & total reward of done eps \n",
    "    \n",
    "    for step in count(1):\n",
    "\n",
    "        # we compute gradients in the train loop\n",
    "        with T.no_grad():\n",
    "            logits, val = policy(ob)\n",
    "            dist = Categorical(logits=logits)\n",
    "            action = dist.sample()\n",
    "        \n",
    "        new_ob, rwd, done, info = env.step(action)\n",
    "        \n",
    "        # store transition\n",
    "        mb['obs'].append(ob)\n",
    "        mb['act'].append(action)\n",
    "        mb['rwd'].append(T.from_numpy(rwd))\n",
    "        mb['val'].append(val.view(-1))\n",
    "        mb['done'].append(T.from_numpy(done))\n",
    "        for t in info:\n",
    "            if t.get('episode'):\n",
    "                ep['l'].append(t['episode']['l'])\n",
    "                ep['r'].append(t['episode']['r'])\n",
    "\n",
    "        ob = ob_to_torch(new_ob)\n",
    "\n",
    "        if step % ROLLOUT_LENGTH != 0:\n",
    "            continue\n",
    "\n",
    "        ########################################################\n",
    "        ###   Flatten rollout & assign credit w/ GAE         ###\n",
    "        ########################################################\n",
    "\n",
    "        # next obs for ICM\n",
    "        mb['nobs'] = mb['obs'][1:] + [ob]\n",
    "\n",
    "        # list(tensor) -> tensor\n",
    "        for k in mb.keys():\n",
    "            mb[k] = T.stack(mb[k]).to(DEVICE)\n",
    "\n",
    "        # bootstap generalized advantages\n",
    "        with T.no_grad():\n",
    "            next_val = policy(ob)[1].view(-1) * ~mb['done'][-1]\n",
    "            mb['rtn'], mb['gae'] = GAE(mb['rwd'], mb['val'], next_val, mb['done'])\n",
    "\n",
    "        # flatten to (NENV*ROLLOUT_LENGTH, ...)\n",
    "        for k in mb.keys():\n",
    "            s = mb[k].size()\n",
    "            mb[k] = mb[k].view(STEPS_PER_ROLLOUT, *s[2:])\n",
    "        \n",
    "        yield mb, ep\n",
    "        mb = {'obs':[], 'nobs':[], 'act':[], 'rwd':[], 'done':[], 'val':[]}\n",
    "        ep = {'l':[], 'r':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nfTbo5W1xigX"
   },
   "source": [
    "# Checkpoint loading and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DW4Hen3sO-JO"
   },
   "outputs": [],
   "source": [
    "def new_run():\n",
    "    \"\"\" setup parallelised gym environments (MaxAndSkip=4 by default) \"\"\"\n",
    "    env = make_atari_env(ENV_NAME, num_env=NENV, seed=SEED)\n",
    "    env._max_episode_steps = 4500*4\n",
    "    env = VecFrameStack(env, n_stack=4)\n",
    "    env = VecNormalize(env, norm_reward=False, clip_reward=1e5, gamma=1.0)\n",
    "    in_dim = env.observation_space.shape\n",
    "    policy_dim = env.action_space.n\n",
    "\n",
    "    # get actor + critic\n",
    "    ac = AC(in_dim, policy_dim).to(DEVICE)\n",
    "    ac_optimizer = Adam(ac.parameters(), 1e-4, eps=1e-5)\n",
    "\n",
    "    # get intrinsic curiosity module\n",
    "    icm = ICM(in_dim, policy_dim, 128).to(DEVICE)\n",
    "    icm_optimizer = Adam(icm.parameters(), 1e-4, eps=1e-5)\n",
    "\n",
    "    logger = Logger(25)\n",
    "\n",
    "    return env, ac, ac_optimizer, icm, icm_optimizer, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMpNi4g-N5dl"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_id):\n",
    "    checkpoint = {\n",
    "        'env': env,\n",
    "        'ac': ac.state_dict(),\n",
    "        'ac_opt': ac_optimizer.state_dict(),\n",
    "        'icm': icm.state_dict(),\n",
    "        'icm_opt': icm_optimizer.state_dict(),\n",
    "        'logger': logger\n",
    "    }\n",
    "    fn = SAVE_PATH+str(checkpoint_id)+ENV_NAME+'.checkpoint.p'\n",
    "    T.save(checkpoint, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Zs4bNIcO66t"
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(file_name):\n",
    "    checkpoint = T.load(file_name)\n",
    "    \n",
    "    venv = make_atari_env(ENV_NAME, num_env=NENV, seed=SEED)\n",
    "    venv = VecFrameStack(venv, n_stack=4)\n",
    "    env = checkpoint['env']\n",
    "    env.set_venv(venv)\n",
    "    in_dim = env.observation_space.shape\n",
    "    policy_dim = env.action_space.n\n",
    "\n",
    "    ac = AC(in_dim, policy_dim).to(DEVICE)\n",
    "    ac.load_state_dict(checkpoint['ac'])\n",
    "    ac_optimizer = Adam(ac.parameters())\n",
    "    ac_optimizer.load_state_dict(checkpoint['ac_opt'])\n",
    "\n",
    "    icm = ICM(in_dim, policy_dim, 128).to(DEVICE)\n",
    "    icm.load_state_dict(checkpoint['icm'])\n",
    "    icm_optimizer = Adam(icm.parameters())\n",
    "    icm_optimizer.load_state_dict(checkpoint['icm_opt'])\n",
    "\n",
    "    logger = checkpoint['logger']\n",
    "\n",
    "    return env, ac, ac_optimizer, icm, icm_optimizer, logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WjmR6d0sxign"
   },
   "source": [
    "# Load checkpoint or begin new run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HllpcNHN_eFa"
   },
   "outputs": [],
   "source": [
    "env, ac, ac_optimizer, icm, icm_optimizer, logger = new_run()\n",
    "# env, ac, ac_optimizer, icm, icm_optimizer, logger = load_checkpoint(SAVE_PATH+'FINAL.BreakoutNoFrameskip-v4.checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8RjFK2rGxigv"
   },
   "source": [
    "# Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9137100,
     "status": "ok",
     "timestamp": 1584656274556,
     "user": {
      "displayName": "Harry Songhurst",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GieNgr7BK-9yyJpoq8YsIhNOD7Lykw7Jg6-uFso=s64",
      "userId": "17177898107918428203"
     },
     "user_tz": 0
    },
    "id": "mUEzq88WsM1l",
    "outputId": "c7e6098e-fd7a-4736-dda6-2c516a7bd46d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- 25 / 4882 ----------\n",
      "Num Games: 150\n",
      "Num Frames: 24576\n",
      "FPS: 435\n",
      "ETA: 3:10:25\n",
      "SMA Length: 172.38\n",
      "SMA Reward: 1.1666666666666667\n",
      "SMA Entropy: 1.2875834008057911\n",
      "SMA Loss: 0.08128672865374635\n",
      "SMA PG Loss: -0.0020430315053090453\n",
      "SMA V Loss: 0.19241118896752596\n",
      "SMA Intrinsic Reward: 0.12199631845578551\n",
      "SMA ICM Loss: 1.128680984179179\n",
      "Max reward: 7.0\n",
      "---------- 50 / 4882 ----------\n",
      "Num Games: 304\n",
      "Num Frames: 50176\n",
      "FPS: 436\n",
      "ETA: 3:08:53\n",
      "SMA Length: 178.51\n",
      "SMA Reward: 1.325\n",
      "SMA Entropy: 1.2775602681296212\n",
      "SMA Loss: 0.05787660939885037\n",
      "SMA PG Loss: -0.0010143948281754035\n",
      "SMA V Loss: 0.14333321366991317\n",
      "SMA Intrinsic Reward: 0.08083587208268594\n",
      "SMA ICM Loss: 1.114181131732707\n",
      "Max reward: 11.0\n",
      "---------- 75 / 4882 ----------\n",
      "Num Games: 449\n",
      "Num Frames: 75776\n",
      "FPS: 438\n",
      "ETA: 3:07:15\n",
      "SMA Length: 188.375\n",
      "SMA Reward: 1.555\n",
      "SMA Entropy: 1.2774185280542116\n",
      "SMA Loss: 0.048230104639220076\n",
      "SMA PG Loss: -0.00017755562313706487\n",
      "SMA V Loss: 0.12236369094131766\n",
      "SMA Intrinsic Reward: 0.0679851724086581\n",
      "SMA ICM Loss: 1.1108211665540129\n",
      "Max reward: 13.0\n",
      "---------- 100 / 4882 ----------\n",
      "Num Games: 585\n",
      "Num Frames: 101376\n",
      "FPS: 438\n",
      "ETA: 3:06:03\n",
      "SMA Length: 200.595\n",
      "SMA Reward: 1.895\n",
      "SMA Entropy: 1.2737530578266492\n",
      "SMA Loss: 0.03914279891460231\n",
      "SMA PG Loss: -0.0019677327099171553\n",
      "SMA V Loss: 0.10769612421140526\n",
      "SMA Intrinsic Reward: 0.06198495592583309\n",
      "SMA ICM Loss: 1.111738166423759\n",
      "Max reward: 13.0\n",
      "---------- 125 / 4882 ----------\n",
      "Num Games: 734\n",
      "Num Frames: 126976\n",
      "FPS: 438\n",
      "ETA: 3:05:08\n",
      "SMA Length: 189.1\n",
      "SMA Reward: 1.66\n",
      "SMA Entropy: 1.2588232746047359\n",
      "SMA Loss: 0.03109442082143599\n",
      "SMA PG Loss: -0.0035510782167435654\n",
      "SMA V Loss: 0.09446746307695585\n",
      "SMA Intrinsic Reward: 0.0592071051078458\n",
      "SMA ICM Loss: 1.10972432840255\n",
      "Max reward: 13.0\n",
      "---------- 150 / 4882 ----------\n",
      "Num Games: 865\n",
      "Num Frames: 152576\n",
      "FPS: 439\n",
      "ETA: 3:03:58\n",
      "SMA Length: 206.92\n",
      "SMA Reward: 2.14\n",
      "SMA Entropy: 1.2488784862044673\n",
      "SMA Loss: 0.027766427731503975\n",
      "SMA PG Loss: -0.0030420410396818746\n",
      "SMA V Loss: 0.08659450679817456\n",
      "SMA Intrinsic Reward: 0.059747145979996495\n",
      "SMA ICM Loss: 1.1054303918108843\n",
      "Max reward: 14.0\n",
      "---------- 175 / 4882 ----------\n",
      "Num Games: 989\n",
      "Num Frames: 178176\n",
      "FPS: 439\n",
      "ETA: 3:02:39\n",
      "SMA Length: 214.91\n",
      "SMA Reward: 2.32\n",
      "SMA Entropy: 1.2424739914378902\n",
      "SMA Loss: 0.02403839834933651\n",
      "SMA PG Loss: -0.0036735053591687105\n",
      "SMA V Loss: 0.08027328676062412\n",
      "SMA Intrinsic Reward: 0.06463627915444045\n",
      "SMA ICM Loss: 1.1002362041637814\n",
      "Max reward: 14.0\n",
      "---------- 200 / 4882 ----------\n",
      "Num Games: 1113\n",
      "Num Frames: 203776\n",
      "FPS: 440\n",
      "ETA: 3:01:26\n",
      "SMA Length: 224.37\n",
      "SMA Reward: 2.545\n",
      "SMA Entropy: 1.2360716584938853\n",
      "SMA Loss: 0.02185317492065717\n",
      "SMA PG Loss: -0.003907880041486205\n",
      "SMA V Loss: 0.0762435426027631\n",
      "SMA Intrinsic Reward: 0.07110081118854446\n",
      "SMA ICM Loss: 1.095275173235179\n",
      "Max reward: 14.0\n",
      "---------- 225 / 4882 ----------\n",
      "Num Games: 1239\n",
      "Num Frames: 229376\n",
      "FPS: 440\n",
      "ETA: 3:00:22\n",
      "SMA Length: 214.785\n",
      "SMA Reward: 2.27\n",
      "SMA Entropy: 1.2274778962135315\n",
      "SMA Loss: 0.013719254853203893\n",
      "SMA PG Loss: -0.004469795452896505\n",
      "SMA V Loss: 0.06092765791341662\n",
      "SMA Intrinsic Reward: 0.07002691341564059\n",
      "SMA ICM Loss: 1.087884179353714\n",
      "Max reward: 14.0\n",
      "---------- 250 / 4882 ----------\n",
      "Num Games: 1367\n",
      "Num Frames: 254976\n",
      "FPS: 441\n",
      "ETA: 2:59:16\n",
      "SMA Length: 212.59\n",
      "SMA Reward: 2.27\n",
      "SMA Entropy: 1.2229730761051179\n",
      "SMA Loss: 0.011515960469841957\n",
      "SMA PG Loss: -0.0056316664209589366\n",
      "SMA V Loss: 0.058754714783281085\n",
      "SMA Intrinsic Reward: 0.07656423786655069\n",
      "SMA ICM Loss: 1.0858542275428773\n",
      "Max reward: 14.0\n",
      "---------- 275 / 4882 ----------\n",
      "Num Games: 1493\n",
      "Num Frames: 280576\n",
      "FPS: 441\n",
      "ETA: 2:58:13\n",
      "SMA Length: 210.485\n",
      "SMA Reward: 2.245\n",
      "SMA Entropy: 1.215429003238678\n",
      "SMA Loss: 0.010254640760831536\n",
      "SMA PG Loss: -0.0076670779613778\n",
      "SMA V Loss: 0.06015201689675451\n",
      "SMA Intrinsic Reward: 0.0852220693975687\n",
      "SMA ICM Loss: 1.0837453263998031\n",
      "Max reward: 14.0\n",
      "---------- 300 / 4882 ----------\n",
      "Num Games: 1613\n",
      "Num Frames: 306176\n",
      "FPS: 441\n",
      "ETA: 2:57:04\n",
      "SMA Length: 228.885\n",
      "SMA Reward: 2.72\n",
      "SMA Entropy: 1.2023390638828277\n",
      "SMA Loss: 0.012680815001949668\n",
      "SMA PG Loss: -0.007929542830679566\n",
      "SMA V Loss: 0.06526749631389976\n",
      "SMA Intrinsic Reward: 0.09750110963359475\n",
      "SMA ICM Loss: 1.0743170815706253\n",
      "Max reward: 14.0\n",
      "---------- 325 / 4882 ----------\n",
      "Num Games: 1736\n",
      "Num Frames: 331776\n",
      "FPS: 442\n",
      "ETA: 2:55:57\n",
      "SMA Length: 226.74\n",
      "SMA Reward: 2.98\n",
      "SMA Entropy: 1.1959705471992492\n",
      "SMA Loss: 0.015453916415572167\n",
      "SMA PG Loss: -0.008325697879772633\n",
      "SMA V Loss: 0.07147863891907036\n",
      "SMA Intrinsic Reward: 0.11227790758013725\n",
      "SMA ICM Loss: 1.0603431576490403\n",
      "Max reward: 14.0\n",
      "---------- 350 / 4882 ----------\n",
      "Num Games: 1851\n",
      "Num Frames: 357376\n",
      "FPS: 442\n",
      "ETA: 2:54:50\n",
      "SMA Length: 225.61\n",
      "SMA Reward: 3.13\n",
      "SMA Entropy: 1.1927356958389281\n",
      "SMA Loss: 0.014786770408973098\n",
      "SMA PG Loss: -0.010516194282099605\n",
      "SMA V Loss: 0.07446064265444875\n",
      "SMA Intrinsic Reward: 0.12671510957181453\n",
      "SMA ICM Loss: 1.0457210642099382\n",
      "Max reward: 14.0\n",
      "---------- 375 / 4882 ----------\n",
      "Num Games: 1962\n",
      "Num Frames: 382976\n",
      "FPS: 442\n",
      "ETA: 2:53:45\n",
      "SMA Length: 241.965\n",
      "SMA Reward: 3.68\n",
      "SMA Entropy: 1.1859160900115966\n",
      "SMA Loss: 0.014012590232305229\n",
      "SMA PG Loss: -0.012911264391150326\n",
      "SMA V Loss: 0.07756603046320379\n",
      "SMA Intrinsic Reward: 0.14297269467264415\n",
      "SMA ICM Loss: 1.024536037147045\n",
      "Max reward: 14.0\n",
      "---------- 400 / 4882 ----------\n",
      "Num Games: 2069\n",
      "Num Frames: 408576\n",
      "FPS: 443\n",
      "ETA: 2:52:39\n",
      "SMA Length: 253.045\n",
      "SMA Reward: 4.11\n",
      "SMA Entropy: 1.180629312992096\n",
      "SMA Loss: 0.013991804225370288\n",
      "SMA PG Loss: -0.015097162381280213\n",
      "SMA V Loss: 0.0817905188165605\n",
      "SMA Intrinsic Reward: 0.15865938395261764\n",
      "SMA ICM Loss: 0.9998582741618156\n",
      "Max reward: 15.0\n",
      "---------- 425 / 4882 ----------\n",
      "Num Games: 2165\n",
      "Num Frames: 434176\n",
      "FPS: 443\n",
      "ETA: 2:51:31\n",
      "SMA Length: 268.045\n",
      "SMA Reward: 4.345\n",
      "SMA Entropy: 1.1634453624486922\n",
      "SMA Loss: 0.013097402676939963\n",
      "SMA PG Loss: -0.017592955662403254\n",
      "SMA V Loss: 0.08464962327852846\n",
      "SMA Intrinsic Reward: 0.17894388914108275\n",
      "SMA ICM Loss: 0.9647321221232414\n",
      "Max reward: 16.0\n",
      "---------- 450 / 4882 ----------\n",
      "Num Games: 2265\n",
      "Num Frames: 459776\n",
      "FPS: 444\n",
      "ETA: 2:50:25\n",
      "SMA Length: 274.965\n",
      "SMA Reward: 4.705\n",
      "SMA Entropy: 1.140733952820301\n",
      "SMA Loss: 0.010585179626941681\n",
      "SMA PG Loss: -0.0203415889875032\n",
      "SMA V Loss: 0.08466821543872356\n",
      "SMA Intrinsic Reward: 0.20331152245402337\n",
      "SMA ICM Loss: 0.9201328772306442\n",
      "Max reward: 16.0\n",
      "---------- 475 / 4882 ----------\n",
      "Num Games: 2376\n",
      "Num Frames: 485376\n",
      "FPS: 443\n",
      "ETA: 2:49:28\n",
      "SMA Length: 257.575\n",
      "SMA Reward: 4.41\n",
      "SMA Entropy: 1.1176135623455048\n",
      "SMA Loss: 0.0075608526263386015\n",
      "SMA PG Loss: -0.022231459154281766\n",
      "SMA V Loss: 0.08193689402192832\n",
      "SMA Intrinsic Reward: 0.22412151843309402\n",
      "SMA ICM Loss: 0.8703341370821\n",
      "Max reward: 16.0\n",
      "---------- 500 / 4882 ----------\n",
      "Num Games: 2472\n",
      "Num Frames: 510976\n",
      "FPS: 444\n",
      "ETA: 2:48:28\n",
      "SMA Length: 260.17\n",
      "SMA Reward: 4.505\n",
      "SMA Entropy: 1.0987896984815597\n",
      "SMA Loss: 0.00445718205999583\n",
      "SMA PG Loss: -0.023279633976053447\n",
      "SMA V Loss: 0.0774494252167642\n",
      "SMA Intrinsic Reward: 0.2406894937902689\n",
      "SMA ICM Loss: 0.8202209779620171\n",
      "Max reward: 17.0\n",
      "---------- 525 / 4882 ----------\n",
      "Num Games: 2569\n",
      "Num Frames: 536576\n",
      "FPS: 444\n",
      "ETA: 2:47:30\n",
      "SMA Length: 276.62\n",
      "SMA Reward: 4.905\n",
      "SMA Entropy: 1.0842768657207489\n",
      "SMA Loss: 0.002786788330413401\n",
      "SMA PG Loss: -0.024218931652139872\n",
      "SMA V Loss: 0.07569697665050626\n",
      "SMA Intrinsic Reward: 0.25206573471426963\n",
      "SMA ICM Loss: 0.7779412788152694\n",
      "Max reward: 17.0\n",
      "---------- 550 / 4882 ----------\n",
      "Num Games: 2678\n",
      "Num Frames: 562176\n",
      "FPS: 444\n",
      "ETA: 2:46:34\n",
      "SMA Length: 260.45\n",
      "SMA Reward: 4.245\n",
      "SMA Entropy: 1.0699021017551422\n",
      "SMA Loss: 0.0038442896865308286\n",
      "SMA PG Loss: -0.023526160672772675\n",
      "SMA V Loss: 0.07613894214853645\n",
      "SMA Intrinsic Reward: 0.2620359019190073\n",
      "SMA ICM Loss: 0.7364546716213226\n",
      "Max reward: 20.0\n",
      "---------- 575 / 4882 ----------\n",
      "Num Games: 2796\n",
      "Num Frames: 587776\n",
      "FPS: 444\n",
      "ETA: 2:45:36\n",
      "SMA Length: 237.155\n",
      "SMA Reward: 3.525\n",
      "SMA Entropy: 1.0588044571876525\n",
      "SMA Loss: 0.0051217535370960835\n",
      "SMA PG Loss: -0.022446600480470806\n",
      "SMA V Loss: 0.07631279649212956\n",
      "SMA Intrinsic Reward: 0.2627368575334549\n",
      "SMA ICM Loss: 0.7038121113181114\n",
      "Max reward: 20.0\n",
      "---------- 600 / 4882 ----------\n",
      "Num Games: 2891\n",
      "Num Frames: 613376\n",
      "FPS: 444\n",
      "ETA: 2:44:31\n",
      "SMA Length: 254.72\n",
      "SMA Reward: 4.425\n",
      "SMA Entropy: 1.0418398457765579\n",
      "SMA Loss: 0.006300851134583354\n",
      "SMA PG Loss: -0.02112211557570845\n",
      "SMA V Loss: 0.07568272974342108\n",
      "SMA Intrinsic Reward: 0.26031464591622355\n",
      "SMA ICM Loss: 0.6687349715828895\n",
      "Max reward: 20.0\n",
      "---------- 625 / 4882 ----------\n",
      "Num Games: 2986\n",
      "Num Frames: 638976\n",
      "FPS: 444\n",
      "ETA: 2:43:26\n",
      "SMA Length: 275.465\n",
      "SMA Reward: 5.21\n",
      "SMA Entropy: 1.0361107382178307\n",
      "SMA Loss: 0.005197609947063028\n",
      "SMA PG Loss: -0.021587276672944425\n",
      "SMA V Loss: 0.07429198741912842\n",
      "SMA Intrinsic Reward: 0.25345522120594977\n",
      "SMA ICM Loss: 0.6439518249034881\n",
      "Max reward: 20.0\n",
      "---------- 650 / 4882 ----------\n",
      "Num Games: 3071\n",
      "Num Frames: 664576\n",
      "FPS: 445\n",
      "ETA: 2:42:20\n",
      "SMA Length: 297.465\n",
      "SMA Reward: 5.695\n",
      "SMA Entropy: 1.0294638252258301\n",
      "SMA Loss: 0.007833586339838803\n",
      "SMA PG Loss: -0.019067951939068736\n",
      "SMA V Loss: 0.07439235266298055\n",
      "SMA Intrinsic Reward: 0.24246662937104702\n",
      "SMA ICM Loss: 0.6250248149037361\n",
      "Max reward: 20.0\n",
      "---------- 675 / 4882 ----------\n",
      "Num Games: 3159\n",
      "Num Frames: 690176\n",
      "FPS: 445\n",
      "ETA: 2:41:15\n",
      "SMA Length: 302.945\n",
      "SMA Reward: 5.695\n",
      "SMA Entropy: 1.0338534983992576\n",
      "SMA Loss: 0.010289112436585129\n",
      "SMA PG Loss: -0.016697046689223498\n",
      "SMA V Loss: 0.07464938782155514\n",
      "SMA Intrinsic Reward: 0.23238496281206608\n",
      "SMA ICM Loss: 0.6169358056783676\n",
      "Max reward: 20.0\n",
      "---------- 700 / 4882 ----------\n",
      "Num Games: 3245\n",
      "Num Frames: 715776\n",
      "FPS: 445\n",
      "ETA: 2:40:10\n",
      "SMA Length: 308.365\n",
      "SMA Reward: 5.615\n",
      "SMA Entropy: 1.042852670252323\n",
      "SMA Loss: 0.009859460070729256\n",
      "SMA PG Loss: -0.01732331683393568\n",
      "SMA V Loss: 0.07522260693833233\n",
      "SMA Intrinsic Reward: 0.22225142151117325\n",
      "SMA ICM Loss: 0.6155058100819588\n",
      "Max reward: 20.0\n",
      "---------- 725 / 4882 ----------\n",
      "Num Games: 3342\n",
      "Num Frames: 741376\n",
      "FPS: 446\n",
      "ETA: 2:39:06\n",
      "SMA Length: 295.81\n",
      "SMA Reward: 5.19\n",
      "SMA Entropy: 1.044645184278488\n",
      "SMA Loss: 0.00903412197716534\n",
      "SMA PG Loss: -0.01724343013949692\n",
      "SMA V Loss: 0.07344800760969519\n",
      "SMA Intrinsic Reward: 0.21249296925961972\n",
      "SMA ICM Loss: 0.6118427357077598\n",
      "Max reward: 20.0\n",
      "---------- 750 / 4882 ----------\n",
      "Num Games: 3439\n",
      "Num Frames: 766976\n",
      "FPS: 446\n",
      "ETA: 2:38:02\n",
      "SMA Length: 285.375\n",
      "SMA Reward: 5.0\n",
      "SMA Entropy: 1.0436661428213119\n",
      "SMA Loss: 0.008120948020368814\n",
      "SMA PG Loss: -0.01787633050698787\n",
      "SMA V Loss: 0.07286787951365113\n",
      "SMA Intrinsic Reward: 0.20183086208999157\n",
      "SMA ICM Loss: 0.6111991709470749\n",
      "Max reward: 20.0\n",
      "---------- 775 / 4882 ----------\n",
      "Num Games: 3525\n",
      "Num Frames: 792576\n",
      "FPS: 446\n",
      "ETA: 2:36:58\n",
      "SMA Length: 299.73\n",
      "SMA Reward: 5.425\n",
      "SMA Entropy: 1.0459597885608674\n",
      "SMA Loss: 0.009110856233164669\n",
      "SMA PG Loss: -0.01642645523417741\n",
      "SMA V Loss: 0.07199381830170751\n",
      "SMA Intrinsic Reward: 0.194596524015069\n",
      "SMA ICM Loss: 0.6125412392616272\n",
      "Max reward: 24.0\n",
      "---------- 800 / 4882 ----------\n",
      "Num Games: 3615\n",
      "Num Frames: 818176\n",
      "FPS: 446\n",
      "ETA: 2:35:55\n",
      "SMA Length: 301.47\n",
      "SMA Reward: 5.585\n",
      "SMA Entropy: 1.0547682589292526\n",
      "SMA Loss: 0.00788285740185529\n",
      "SMA PG Loss: -0.0169425162486732\n",
      "SMA V Loss: 0.07074611203745007\n",
      "SMA Intrinsic Reward: 0.1889172051846981\n",
      "SMA ICM Loss: 0.6191973268985749\n",
      "Max reward: 24.0\n",
      "---------- 825 / 4882 ----------\n",
      "Num Games: 3700\n",
      "Num Frames: 843776\n",
      "FPS: 447\n",
      "ETA: 2:34:53\n",
      "SMA Length: 306.75\n",
      "SMA Reward: 5.95\n",
      "SMA Entropy: 1.0581109163165092\n",
      "SMA Loss: 0.00884658167604357\n",
      "SMA PG Loss: -0.014999012043699623\n",
      "SMA V Loss: 0.06885340526700019\n",
      "SMA Intrinsic Reward: 0.18267307110130787\n",
      "SMA ICM Loss: 0.6217632290720939\n",
      "Max reward: 24.0\n",
      "---------- 850 / 4882 ----------\n",
      "Num Games: 3791\n",
      "Num Frames: 869376\n",
      "FPS: 447\n",
      "ETA: 2:33:51\n",
      "SMA Length: 306.645\n",
      "SMA Reward: 6.195\n",
      "SMA Entropy: 1.0636843556165696\n",
      "SMA Loss: 0.006870971731841564\n",
      "SMA PG Loss: -0.015814064382575453\n",
      "SMA V Loss: 0.06664375880733132\n",
      "SMA Intrinsic Reward: 0.17881479881703854\n",
      "SMA ICM Loss: 0.6211626467108726\n",
      "Max reward: 24.0\n",
      "---------- 875 / 4882 ----------\n",
      "Num Games: 3881\n",
      "Num Frames: 894976\n",
      "FPS: 447\n",
      "ETA: 2:32:49\n",
      "SMA Length: 297.185\n",
      "SMA Reward: 6.015\n",
      "SMA Entropy: 1.054566506445408\n",
      "SMA Loss: 0.00543471097946167\n",
      "SMA PG Loss: -0.01661155395908281\n",
      "SMA V Loss: 0.06518385944887996\n",
      "SMA Intrinsic Reward: 0.1748634971678257\n",
      "SMA ICM Loss: 0.6104508870840073\n",
      "Max reward: 24.0\n",
      "---------- 900 / 4882 ----------\n",
      "Num Games: 3972\n",
      "Num Frames: 920576\n",
      "FPS: 447\n",
      "ETA: 2:31:48\n",
      "SMA Length: 290.135\n",
      "SMA Reward: 5.75\n",
      "SMA Entropy: 1.0428243780136108\n",
      "SMA Loss: 0.006588274706155061\n",
      "SMA PG Loss: -0.015185635744128376\n",
      "SMA V Loss: 0.06440430775284767\n",
      "SMA Intrinsic Reward: 0.17026558838784694\n",
      "SMA ICM Loss: 0.600215810984373\n",
      "Max reward: 24.0\n",
      "---------- 925 / 4882 ----------\n",
      "Num Games: 4057\n",
      "Num Frames: 946176\n",
      "FPS: 448\n",
      "ETA: 2:30:46\n",
      "SMA Length: 309.58\n",
      "SMA Reward: 6.52\n",
      "SMA Entropy: 1.0321816802024841\n",
      "SMA Loss: 0.007616660189814866\n",
      "SMA PG Loss: -0.014434261189308017\n",
      "SMA V Loss: 0.06474547570571304\n",
      "SMA Intrinsic Reward: 0.16656249083578586\n",
      "SMA ICM Loss: 0.5877825574576855\n",
      "Max reward: 25.0\n",
      "---------- 950 / 4882 ----------\n",
      "Num Games: 4138\n",
      "Num Frames: 971776\n",
      "FPS: 448\n",
      "ETA: 2:29:44\n",
      "SMA Length: 323.715\n",
      "SMA Reward: 6.965\n",
      "SMA Entropy: 1.01800053358078\n",
      "SMA Loss: 0.008812704915180802\n",
      "SMA PG Loss: -0.01298668330651708\n",
      "SMA V Loss: 0.06395878655835986\n",
      "SMA Intrinsic Reward: 0.1629444708302617\n",
      "SMA ICM Loss: 0.5706764207780362\n",
      "Max reward: 25.0\n",
      "---------- 975 / 4882 ----------\n",
      "Num Games: 4227\n",
      "Num Frames: 997376\n",
      "FPS: 448\n",
      "ETA: 2:28:43\n",
      "SMA Length: 318.98\n",
      "SMA Reward: 6.745\n",
      "SMA Entropy: 1.0013764324784278\n",
      "SMA Loss: 0.005882741417735815\n",
      "SMA PG Loss: -0.015790160485776143\n",
      "SMA V Loss: 0.0633733319863677\n",
      "SMA Intrinsic Reward: 0.1587932475656271\n",
      "SMA ICM Loss: 0.5521418751776218\n",
      "Max reward: 25.0\n",
      "---------- 1000 / 4882 ----------\n",
      "Num Games: 4314\n",
      "Num Frames: 1022976\n",
      "FPS: 448\n",
      "ETA: 2:27:43\n",
      "SMA Length: 312.43\n",
      "SMA Reward: 6.655\n",
      "SMA Entropy: 0.978638765513897\n",
      "SMA Loss: 0.0058995839254930614\n",
      "SMA PG Loss: -0.01566746103693731\n",
      "SMA V Loss: 0.06270686473697423\n",
      "SMA Intrinsic Reward: 0.15309702880680562\n",
      "SMA ICM Loss: 0.5323372061550617\n",
      "Max reward: 25.0\n",
      "---------- 1025 / 4882 ----------\n",
      "Num Games: 4401\n",
      "Num Frames: 1048576\n",
      "FPS: 448\n",
      "ETA: 2:26:43\n",
      "SMA Length: 308.04\n",
      "SMA Reward: 6.695\n",
      "SMA Entropy: 0.9549080088734627\n",
      "SMA Loss: 0.006005349205806852\n",
      "SMA PG Loss: -0.01610812145867385\n",
      "SMA V Loss: 0.063325101044029\n",
      "SMA Intrinsic Reward: 0.1479628274589777\n",
      "SMA ICM Loss: 0.5121935126185417\n",
      "Max reward: 25.0\n",
      "---------- 1050 / 4882 ----------\n",
      "Num Games: 4486\n",
      "Num Frames: 1074176\n",
      "FPS: 449\n",
      "ETA: 2:25:42\n",
      "SMA Length: 310.12\n",
      "SMA Reward: 6.65\n",
      "SMA Entropy: 0.9348827359080315\n",
      "SMA Loss: 0.00891215642914176\n",
      "SMA PG Loss: -0.013541321038501338\n",
      "SMA V Loss: 0.06360460931435227\n",
      "SMA Intrinsic Reward: 0.14225543212145567\n",
      "SMA ICM Loss: 0.4973571938276291\n",
      "Max reward: 25.0\n",
      "---------- 1075 / 4882 ----------\n",
      "Num Games: 4567\n",
      "Num Frames: 1099776\n",
      "FPS: 449\n",
      "ETA: 2:24:41\n",
      "SMA Length: 329.02\n",
      "SMA Reward: 7.005\n",
      "SMA Entropy: 0.9260788723826409\n",
      "SMA Loss: 0.008881200510077179\n",
      "SMA PG Loss: -0.013987656919052825\n",
      "SMA V Loss: 0.06425929209217429\n",
      "SMA Intrinsic Reward: 0.13623642697930335\n",
      "SMA ICM Loss: 0.4915861578285694\n",
      "Max reward: 25.0\n",
      "---------- 1100 / 4882 ----------\n",
      "Num Games: 4653\n",
      "Num Frames: 1125376\n",
      "FPS: 449\n",
      "ETA: 2:23:41\n",
      "SMA Length: 324.945\n",
      "SMA Reward: 6.76\n",
      "SMA Entropy: 0.9190154868364334\n",
      "SMA Loss: 0.009533269172534347\n",
      "SMA PG Loss: -0.013756753032794222\n",
      "SMA V Loss: 0.06496035404503346\n",
      "SMA Intrinsic Reward: 0.13093165144324304\n",
      "SMA ICM Loss: 0.4859207823872566\n",
      "Max reward: 25.0\n",
      "---------- 1125 / 4882 ----------\n",
      "Num Games: 4735\n",
      "Num Frames: 1150976\n",
      "FPS: 449\n",
      "ETA: 2:22:40\n",
      "SMA Length: 318.16\n",
      "SMA Reward: 6.565\n",
      "SMA Entropy: 0.9106172889471054\n",
      "SMA Loss: 0.010210760496556759\n",
      "SMA PG Loss: -0.012958280773600563\n",
      "SMA V Loss: 0.0645504280552268\n",
      "SMA Intrinsic Reward: 0.12625663366168738\n",
      "SMA ICM Loss: 0.4790059094130993\n",
      "Max reward: 25.0\n",
      "---------- 1150 / 4882 ----------\n",
      "Num Games: 4820\n",
      "Num Frames: 1176576\n",
      "FPS: 449\n",
      "ETA: 2:21:40\n",
      "SMA Length: 310.995\n",
      "SMA Reward: 6.3\n",
      "SMA Entropy: 0.9139707398414612\n",
      "SMA Loss: 0.009975246274843813\n",
      "SMA PG Loss: -0.012815049085766077\n",
      "SMA V Loss: 0.06386000521481038\n",
      "SMA Intrinsic Reward: 0.12248123683035374\n",
      "SMA ICM Loss: 0.48110297694802284\n",
      "Max reward: 25.0\n",
      "---------- 1175 / 4882 ----------\n",
      "Num Games: 4907\n",
      "Num Frames: 1202176\n",
      "FPS: 450\n",
      "ETA: 2:20:39\n",
      "SMA Length: 321.5\n",
      "SMA Reward: 6.61\n",
      "SMA Entropy: 0.9186492827534676\n",
      "SMA Loss: 0.012664821343496441\n",
      "SMA PG Loss: -0.010311614954844117\n",
      "SMA V Loss: 0.06432585798203945\n",
      "SMA Intrinsic Reward: 0.1191944109648466\n",
      "SMA ICM Loss: 0.4844985517859459\n",
      "Max reward: 26.0\n",
      "---------- 1200 / 4882 ----------\n",
      "Num Games: 4986\n",
      "Num Frames: 1227776\n",
      "FPS: 450\n",
      "ETA: 2:19:38\n",
      "SMA Length: 320.965\n",
      "SMA Reward: 6.75\n",
      "SMA Entropy: 0.9281324502825737\n",
      "SMA Loss: 0.012086403616704046\n",
      "SMA PG Loss: -0.010983320369850844\n",
      "SMA V Loss: 0.06470209687948227\n",
      "SMA Intrinsic Reward: 0.11667953740805387\n",
      "SMA ICM Loss: 0.4873147168755531\n",
      "Max reward: 26.0\n",
      "---------- 1225 / 4882 ----------\n",
      "Num Games: 5068\n",
      "Num Frames: 1253376\n",
      "FPS: 450\n",
      "ETA: 2:18:38\n",
      "SMA Length: 326.215\n",
      "SMA Reward: 6.835\n",
      "SMA Entropy: 0.9441009479761123\n",
      "SMA Loss: 0.0130295266257599\n",
      "SMA PG Loss: -0.010130180574487896\n",
      "SMA V Loss: 0.06520143333822488\n",
      "SMA Intrinsic Reward: 0.11439770121127367\n",
      "SMA ICM Loss: 0.49874823972582816\n",
      "Max reward: 26.0\n",
      "---------- 1250 / 4882 ----------\n",
      "Num Games: 5158\n",
      "Num Frames: 1278976\n",
      "FPS: 450\n",
      "ETA: 2:17:40\n",
      "SMA Length: 315.865\n",
      "SMA Reward: 6.19\n",
      "SMA Entropy: 0.9614536336064339\n",
      "SMA Loss: 0.011550986589863897\n",
      "SMA PG Loss: -0.011428261816035956\n",
      "SMA V Loss: 0.06518756940960885\n",
      "SMA Intrinsic Reward: 0.11221370685845614\n",
      "SMA ICM Loss: 0.51261544033885\n",
      "Max reward: 26.0\n",
      "---------- 1275 / 4882 ----------\n",
      "Num Games: 5239\n",
      "Num Frames: 1304576\n",
      "FPS: 450\n",
      "ETA: 2:16:44\n",
      "SMA Length: 312.915\n",
      "SMA Reward: 6.305\n",
      "SMA Entropy: 0.9734503132104874\n",
      "SMA Loss: 0.011838214662857354\n",
      "SMA PG Loss: -0.011046017925255001\n",
      "SMA V Loss: 0.06523747127503157\n",
      "SMA Intrinsic Reward: 0.11052210830152034\n",
      "SMA ICM Loss: 0.5213445729017258\n",
      "Max reward: 26.0\n",
      "---------- 1300 / 4882 ----------\n",
      "Num Games: 5320\n",
      "Num Frames: 1330176\n",
      "FPS: 450\n",
      "ETA: 2:15:47\n",
      "SMA Length: 324.765\n",
      "SMA Reward: 6.605\n",
      "SMA Entropy: 0.9857801878452301\n",
      "SMA Loss: 0.011008960180915892\n",
      "SMA PG Loss: -0.010934624432120472\n",
      "SMA V Loss: 0.06360277276486158\n",
      "SMA Intrinsic Reward: 0.10961244329810142\n",
      "SMA ICM Loss: 0.527658098936081\n",
      "Max reward: 26.0\n",
      "---------- 1325 / 4882 ----------\n",
      "Num Games: 5399\n",
      "Num Frames: 1355776\n",
      "FPS: 450\n",
      "ETA: 2:14:50\n",
      "SMA Length: 321.2\n",
      "SMA Reward: 6.76\n",
      "SMA Entropy: 1.0004730501770973\n",
      "SMA Loss: 0.010335074067115783\n",
      "SMA PG Loss: -0.011570862897206097\n",
      "SMA V Loss: 0.06382133470848203\n",
      "SMA Intrinsic Reward: 0.10825561352074146\n",
      "SMA ICM Loss: 0.5385600993037224\n",
      "Max reward: 27.0\n",
      "---------- 1350 / 4882 ----------\n",
      "Num Games: 5481\n",
      "Num Frames: 1381376\n",
      "FPS: 450\n",
      "ETA: 2:13:51\n",
      "SMA Length: 325.88\n",
      "SMA Reward: 6.825\n",
      "SMA Entropy: 1.0071583783626556\n",
      "SMA Loss: 0.009030896108597516\n",
      "SMA PG Loss: -0.013012441201135516\n",
      "SMA V Loss: 0.06422984200529754\n",
      "SMA Intrinsic Reward: 0.1072002824395895\n",
      "SMA ICM Loss: 0.542955396771431\n",
      "Max reward: 27.0\n",
      "---------- 1375 / 4882 ----------\n",
      "Num Games: 5553\n",
      "Num Frames: 1406976\n",
      "FPS: 450\n",
      "ETA: 2:12:52\n",
      "SMA Length: 344.775\n",
      "SMA Reward: 7.535\n",
      "SMA Entropy: 1.0049543690681457\n",
      "SMA Loss: 0.009867448615841568\n",
      "SMA PG Loss: -0.013023956520482898\n",
      "SMA V Loss: 0.06588189751841128\n",
      "SMA Intrinsic Reward: 0.1056389420107007\n",
      "SMA ICM Loss: 0.538746353983879\n",
      "Max reward: 27.0\n",
      "---------- 1400 / 4882 ----------\n",
      "Num Games: 5634\n",
      "Num Frames: 1432576\n",
      "FPS: 450\n",
      "ETA: 2:11:52\n",
      "SMA Length: 338.865\n",
      "SMA Reward: 7.425\n",
      "SMA Entropy: 1.0030711317062377\n",
      "SMA Loss: 0.01111547082196921\n",
      "SMA PG Loss: -0.011405702054034919\n",
      "SMA V Loss: 0.06510376812890172\n",
      "SMA Intrinsic Reward: 0.10452660474926233\n",
      "SMA ICM Loss: 0.5360483729839325\n",
      "Max reward: 27.0\n",
      "---------- 1425 / 4882 ----------\n",
      "Num Games: 5716\n",
      "Num Frames: 1458176\n",
      "FPS: 451\n",
      "ETA: 2:10:52\n",
      "SMA Length: 334.72\n",
      "SMA Reward: 7.505\n",
      "SMA Entropy: 0.9961920487880707\n",
      "SMA Loss: 0.01136318983975798\n",
      "SMA PG Loss: -0.01122781666694209\n",
      "SMA V Loss: 0.0651058535836637\n",
      "SMA Intrinsic Reward: 0.10269254043698312\n",
      "SMA ICM Loss: 0.5290194350481033\n",
      "Max reward: 27.0\n",
      "---------- 1450 / 4882 ----------\n",
      "Num Games: 5795\n",
      "Num Frames: 1483776\n",
      "FPS: 451\n",
      "ETA: 2:09:53\n",
      "SMA Length: 329.215\n",
      "SMA Reward: 7.23\n",
      "SMA Entropy: 0.9872439250349998\n",
      "SMA Loss: 0.009717135592363774\n",
      "SMA PG Loss: -0.013205718242097646\n",
      "SMA V Loss: 0.06559058578684926\n",
      "SMA Intrinsic Reward: 0.10065203718841076\n",
      "SMA ICM Loss: 0.5179689419269562\n",
      "Max reward: 27.0\n",
      "---------- 1475 / 4882 ----------\n",
      "Num Games: 5877\n",
      "Num Frames: 1509376\n",
      "FPS: 451\n",
      "ETA: 2:08:54\n",
      "SMA Length: 340.965\n",
      "SMA Reward: 7.67\n",
      "SMA Entropy: 0.9787201711535454\n",
      "SMA Loss: 0.011058756886050104\n",
      "SMA PG Loss: -0.011986116974148898\n",
      "SMA V Loss: 0.06566415073350072\n",
      "SMA Intrinsic Reward: 0.0990585670992732\n",
      "SMA ICM Loss: 0.5070275247097016\n",
      "Max reward: 27.0\n",
      "---------- 1500 / 4882 ----------\n",
      "Num Games: 5959\n",
      "Num Frames: 1534976\n",
      "FPS: 451\n",
      "ETA: 2:07:54\n",
      "SMA Length: 322.99\n",
      "SMA Reward: 6.8\n",
      "SMA Entropy: 0.9706272485852242\n",
      "SMA Loss: 0.010587863763794303\n",
      "SMA PG Loss: -0.012492684358730912\n",
      "SMA V Loss: 0.0655736408662051\n",
      "SMA Intrinsic Reward: 0.09678574942052365\n",
      "SMA ICM Loss: 0.49963736683130267\n",
      "Max reward: 27.0\n",
      "---------- 1525 / 4882 ----------\n",
      "Num Games: 6040\n",
      "Num Frames: 1560576\n",
      "FPS: 451\n",
      "ETA: 2:06:56\n",
      "SMA Length: 327.725\n",
      "SMA Reward: 6.945\n",
      "SMA Entropy: 0.9656115317344666\n",
      "SMA Loss: 0.0113113136542961\n",
      "SMA PG Loss: -0.011951991389505565\n",
      "SMA V Loss: 0.06583884057588875\n",
      "SMA Intrinsic Reward: 0.09511775739490985\n",
      "SMA ICM Loss: 0.49063933283090594\n",
      "Max reward: 27.0\n",
      "---------- 1550 / 4882 ----------\n",
      "Num Games: 6115\n",
      "Num Frames: 1586176\n",
      "FPS: 451\n",
      "ETA: 2:05:58\n",
      "SMA Length: 338.675\n",
      "SMA Reward: 7.46\n",
      "SMA Entropy: 0.9589301082491875\n",
      "SMA Loss: 0.011052060681395233\n",
      "SMA PG Loss: -0.012624850866850466\n",
      "SMA V Loss: 0.06653242507949471\n",
      "SMA Intrinsic Reward: 0.09298771351575852\n",
      "SMA ICM Loss: 0.4822562472522259\n",
      "Max reward: 27.0\n",
      "---------- 1575 / 4882 ----------\n",
      "Num Games: 6195\n",
      "Num Frames: 1611776\n",
      "FPS: 451\n",
      "ETA: 2:04:59\n",
      "SMA Length: 334.085\n",
      "SMA Reward: 7.24\n",
      "SMA Entropy: 0.9543586945533753\n",
      "SMA Loss: 0.010272531136870384\n",
      "SMA PG Loss: -0.012727378432173283\n",
      "SMA V Loss: 0.06508699277415872\n",
      "SMA Intrinsic Reward: 0.09132505517452955\n",
      "SMA ICM Loss: 0.4762708133459091\n",
      "Max reward: 27.0\n",
      "---------- 1600 / 4882 ----------\n",
      "Num Games: 6275\n",
      "Num Frames: 1637376\n",
      "FPS: 451\n",
      "ETA: 2:04:00\n",
      "SMA Length: 334.01\n",
      "SMA Reward: 7.215\n",
      "SMA Entropy: 0.9506432482600212\n",
      "SMA Loss: 0.011001885691657663\n",
      "SMA PG Loss: -0.012751635110471398\n",
      "SMA V Loss: 0.06651990621350706\n",
      "SMA Intrinsic Reward: 0.08908040031790733\n",
      "SMA ICM Loss: 0.4716490465402603\n",
      "Max reward: 27.0\n",
      "---------- 1625 / 4882 ----------\n",
      "Num Games: 6354\n",
      "Num Frames: 1662976\n",
      "FPS: 452\n",
      "ETA: 2:03:02\n",
      "SMA Length: 339.075\n",
      "SMA Reward: 7.375\n",
      "SMA Entropy: 0.9527527448534966\n",
      "SMA Loss: 0.00991115091368556\n",
      "SMA PG Loss: -0.013451893690507859\n",
      "SMA V Loss: 0.06578114377334714\n",
      "SMA Intrinsic Reward: 0.08748979777097703\n",
      "SMA ICM Loss: 0.47014713257551194\n",
      "Max reward: 27.0\n",
      "---------- 1650 / 4882 ----------\n",
      "Num Games: 6431\n",
      "Num Frames: 1688576\n",
      "FPS: 452\n",
      "ETA: 2:02:04\n",
      "SMA Length: 349.505\n",
      "SMA Reward: 7.675\n",
      "SMA Entropy: 0.9523875811696052\n",
      "SMA Loss: 0.009748432314954697\n",
      "SMA PG Loss: -0.013112505697645247\n",
      "SMA V Loss: 0.06476962726563215\n",
      "SMA Intrinsic Reward: 0.08603737615048886\n",
      "SMA ICM Loss: 0.4686158028244972\n",
      "Max reward: 27.0\n",
      "---------- 1675 / 4882 ----------\n",
      "Num Games: 6511\n",
      "Num Frames: 1714176\n",
      "FPS: 452\n",
      "ETA: 2:01:06\n",
      "SMA Length: 340.37\n",
      "SMA Reward: 7.19\n",
      "SMA Entropy: 0.9505966058373452\n",
      "SMA Loss: 0.009307562462054194\n",
      "SMA PG Loss: -0.013361045196652412\n",
      "SMA V Loss: 0.06434914702549577\n",
      "SMA Intrinsic Reward: 0.08401009775698184\n",
      "SMA ICM Loss: 0.46655110955238344\n",
      "Max reward: 27.0\n",
      "---------- 1700 / 4882 ----------\n",
      "Num Games: 6593\n",
      "Num Frames: 1739776\n",
      "FPS: 452\n",
      "ETA: 2:00:09\n",
      "SMA Length: 336.705\n",
      "SMA Reward: 7.075\n",
      "SMA Entropy: 0.9501224833726883\n",
      "SMA Loss: 0.009134106170386076\n",
      "SMA PG Loss: -0.013766182970721274\n",
      "SMA V Loss: 0.0648030274733901\n",
      "SMA Intrinsic Reward: 0.08220803882926703\n",
      "SMA ICM Loss: 0.4659934467077255\n",
      "Max reward: 27.0\n",
      "---------- 1725 / 4882 ----------\n",
      "Num Games: 6668\n",
      "Num Frames: 1765376\n",
      "FPS: 452\n",
      "ETA: 1:59:11\n",
      "SMA Length: 336.98\n",
      "SMA Reward: 7.165\n",
      "SMA Entropy: 0.9456785178184509\n",
      "SMA Loss: 0.007323402725160122\n",
      "SMA PG Loss: -0.016270069333259016\n",
      "SMA V Loss: 0.06610051380470396\n",
      "SMA Intrinsic Reward: 0.08075025863945484\n",
      "SMA ICM Loss: 0.46253712847828865\n",
      "Max reward: 27.0\n",
      "---------- 1750 / 4882 ----------\n",
      "Num Games: 6737\n",
      "Num Frames: 1790976\n",
      "FPS: 452\n",
      "ETA: 1:58:13\n",
      "SMA Length: 355.675\n",
      "SMA Reward: 8.17\n",
      "SMA Entropy: 0.9433337590098381\n",
      "SMA Loss: 0.008503858312033118\n",
      "SMA PG Loss: -0.01563241322757676\n",
      "SMA V Loss: 0.06713921761140228\n",
      "SMA Intrinsic Reward: 0.07945044141262769\n",
      "SMA ICM Loss: 0.4596994261443615\n",
      "Max reward: 27.0\n",
      "---------- 1775 / 4882 ----------\n",
      "Num Games: 6814\n",
      "Num Frames: 1816576\n",
      "FPS: 452\n",
      "ETA: 1:57:16\n",
      "SMA Length: 357.65\n",
      "SMA Reward: 8.51\n",
      "SMA Entropy: 0.9424003559350967\n",
      "SMA Loss: 0.009008859028108418\n",
      "SMA PG Loss: -0.015585247594863176\n",
      "SMA V Loss: 0.06803621964529157\n",
      "SMA Intrinsic Reward: 0.07829162485897541\n",
      "SMA ICM Loss: 0.458567114174366\n",
      "Max reward: 27.0\n",
      "---------- 1800 / 4882 ----------\n",
      "Num Games: 6899\n",
      "Num Frames: 1842176\n",
      "FPS: 452\n",
      "ETA: 1:56:20\n",
      "SMA Length: 337.02\n",
      "SMA Reward: 7.49\n",
      "SMA Entropy: 0.9428727665543556\n",
      "SMA Loss: 0.0067680599167943\n",
      "SMA PG Loss: -0.01732351259328425\n",
      "SMA V Loss: 0.06704059988260269\n",
      "SMA Intrinsic Reward: 0.07663634214550256\n",
      "SMA ICM Loss: 0.4644295971095562\n",
      "Max reward: 27.0\n",
      "---------- 1825 / 4882 ----------\n",
      "Num Games: 6972\n",
      "Num Frames: 1867776\n",
      "FPS: 452\n",
      "ETA: 1:55:23\n",
      "SMA Length: 337.38\n",
      "SMA Reward: 7.335\n",
      "SMA Entropy: 0.9399816834926605\n",
      "SMA Loss: 0.005893219467252493\n",
      "SMA PG Loss: -0.018427329934202135\n",
      "SMA V Loss: 0.06744073220528662\n",
      "SMA Intrinsic Reward: 0.07541316863149404\n",
      "SMA ICM Loss: 0.4624619588255882\n",
      "Max reward: 27.0\n",
      "---------- 1850 / 4882 ----------\n",
      "Num Games: 7047\n",
      "Num Frames: 1893376\n",
      "FPS: 452\n",
      "ETA: 1:54:26\n",
      "SMA Length: 341.09\n",
      "SMA Reward: 7.58\n",
      "SMA Entropy: 0.9309472042322159\n",
      "SMA Loss: 0.006944743129424751\n",
      "SMA PG Loss: -0.01794654126977548\n",
      "SMA V Loss: 0.0684015126246959\n",
      "SMA Intrinsic Reward: 0.07446174629032612\n",
      "SMA ICM Loss: 0.45512281835079194\n",
      "Max reward: 27.0\n",
      "---------- 1875 / 4882 ----------\n",
      "Num Games: 7133\n",
      "Num Frames: 1918976\n",
      "FPS: 452\n",
      "ETA: 1:53:29\n",
      "SMA Length: 336.845\n",
      "SMA Reward: 7.675\n",
      "SMA Entropy: 0.9242401710152626\n",
      "SMA Loss: 0.007521425937302411\n",
      "SMA PG Loss: -0.017643709413241594\n",
      "SMA V Loss: 0.06881507377140224\n",
      "SMA Intrinsic Reward: 0.07339676219969987\n",
      "SMA ICM Loss: 0.45233252048492434\n",
      "Max reward: 27.0\n",
      "---------- 1900 / 4882 ----------\n",
      "Num Games: 7203\n",
      "Num Frames: 1944576\n",
      "FPS: 452\n",
      "ETA: 1:52:31\n",
      "SMA Length: 347.03\n",
      "SMA Reward: 8.09\n",
      "SMA Entropy: 0.9201518663764\n",
      "SMA Loss: 0.009762722593732178\n",
      "SMA PG Loss: -0.01571193553507328\n",
      "SMA V Loss: 0.06935235338285566\n",
      "SMA Intrinsic Reward: 0.07268034294247627\n",
      "SMA ICM Loss: 0.4472001613676548\n",
      "Max reward: 27.0\n",
      "---------- 1925 / 4882 ----------\n",
      "Num Games: 7278\n",
      "Num Frames: 1970176\n",
      "FPS: 452\n",
      "ETA: 1:51:34\n",
      "SMA Length: 354.585\n",
      "SMA Reward: 8.39\n",
      "SMA Entropy: 0.918642657995224\n",
      "SMA Loss: 0.010788105381652712\n",
      "SMA PG Loss: -0.01406483746599406\n",
      "SMA V Loss: 0.06807873867452145\n",
      "SMA Intrinsic Reward: 0.07170301456004381\n",
      "SMA ICM Loss: 0.4445557801425457\n",
      "Max reward: 27.0\n",
      "---------- 1950 / 4882 ----------\n",
      "Num Games: 7352\n",
      "Num Frames: 1995776\n",
      "FPS: 452\n",
      "ETA: 1:50:37\n",
      "SMA Length: 366.39\n",
      "SMA Reward: 8.47\n",
      "SMA Entropy: 0.9207191860675812\n",
      "SMA Loss: 0.010489557273685932\n",
      "SMA PG Loss: -0.013953649527393282\n",
      "SMA V Loss: 0.06730079712346196\n",
      "SMA Intrinsic Reward: 0.07078721871599555\n",
      "SMA ICM Loss: 0.44485109582543375\n",
      "Max reward: 27.0\n",
      "---------- 1975 / 4882 ----------\n",
      "Num Games: 7423\n",
      "Num Frames: 2021376\n",
      "FPS: 452\n",
      "ETA: 1:49:40\n",
      "SMA Length: 367.13\n",
      "SMA Reward: 8.655\n",
      "SMA Entropy: 0.9219673439860344\n",
      "SMA Loss: 0.009277448672801256\n",
      "SMA PG Loss: -0.015220006776507944\n",
      "SMA V Loss: 0.06743425766006111\n",
      "SMA Intrinsic Reward: 0.06960145255550743\n",
      "SMA ICM Loss: 0.4439157602190971\n",
      "Max reward: 27.0\n",
      "---------- 2000 / 4882 ----------\n",
      "Num Games: 7500\n",
      "Num Frames: 2046976\n",
      "FPS: 452\n",
      "ETA: 1:48:42\n",
      "SMA Length: 359.69\n",
      "SMA Reward: 8.67\n",
      "SMA Entropy: 0.9190867400169372\n",
      "SMA Loss: 0.010032189106568693\n",
      "SMA PG Loss: -0.015199715483468025\n",
      "SMA V Loss: 0.06884554371237755\n",
      "SMA Intrinsic Reward: 0.06938557228073478\n",
      "SMA ICM Loss: 0.43504242435097695\n",
      "Max reward: 28.0\n",
      "---------- 2025 / 4882 ----------\n",
      "Num Games: 7571\n",
      "Num Frames: 2072576\n",
      "FPS: 452\n",
      "ETA: 1:47:45\n",
      "SMA Length: 356.12\n",
      "SMA Reward: 8.79\n",
      "SMA Entropy: 0.9135088381171227\n",
      "SMA Loss: 0.011847933526150883\n",
      "SMA PG Loss: -0.01371864605229348\n",
      "SMA V Loss: 0.06940333547070622\n",
      "SMA Intrinsic Reward: 0.06847078451886773\n",
      "SMA ICM Loss: 0.43088956356048586\n",
      "Max reward: 28.0\n",
      "---------- 2050 / 4882 ----------\n",
      "Num Games: 7655\n",
      "Num Frames: 2098176\n",
      "FPS: 452\n",
      "ETA: 1:46:48\n",
      "SMA Length: 343.165\n",
      "SMA Reward: 8.315\n",
      "SMA Entropy: 0.9169779771566391\n",
      "SMA Loss: 0.00975093004759401\n",
      "SMA PG Loss: -0.01588831386528909\n",
      "SMA V Loss: 0.06961804689839482\n",
      "SMA Intrinsic Reward: 0.06771357392892241\n",
      "SMA ICM Loss: 0.4341582001745701\n",
      "Max reward: 28.0\n",
      "---------- 2075 / 4882 ----------\n",
      "Num Games: 7725\n",
      "Num Frames: 2123776\n",
      "FPS: 452\n",
      "ETA: 1:45:51\n",
      "SMA Length: 350.565\n",
      "SMA Reward: 8.355\n",
      "SMA Entropy: 0.918792744576931\n",
      "SMA Loss: 0.01032725020777434\n",
      "SMA PG Loss: -0.015598340779542924\n",
      "SMA V Loss: 0.07022703647613525\n",
      "SMA Intrinsic Reward: 0.06745770717039705\n",
      "SMA ICM Loss: 0.4326094101369381\n",
      "Max reward: 28.0\n",
      "---------- 2100 / 4882 ----------\n",
      "Num Games: 7796\n",
      "Num Frames: 2149376\n",
      "FPS: 452\n",
      "ETA: 1:44:54\n",
      "SMA Length: 361.705\n",
      "SMA Reward: 8.595\n",
      "SMA Entropy: 0.9163853272795677\n",
      "SMA Loss: 0.008922837120480835\n",
      "SMA PG Loss: -0.016814094681758433\n",
      "SMA V Loss: 0.06980156956240535\n",
      "SMA Intrinsic Reward: 0.06662695256993174\n",
      "SMA ICM Loss: 0.43318269461393355\n",
      "Max reward: 28.0\n",
      "---------- 2125 / 4882 ----------\n",
      "Num Games: 7866\n",
      "Num Frames: 2174976\n",
      "FPS: 452\n",
      "ETA: 1:43:58\n",
      "SMA Length: 379.02\n",
      "SMA Reward: 9.285\n",
      "SMA Entropy: 0.9130538126826286\n",
      "SMA Loss: 0.007845375309698284\n",
      "SMA PG Loss: -0.01751532291295007\n",
      "SMA V Loss: 0.06898247214034199\n",
      "SMA Intrinsic Reward: 0.06602947784587741\n",
      "SMA ICM Loss: 0.4309369468688965\n",
      "Max reward: 28.0\n",
      "---------- 2150 / 4882 ----------\n",
      "Num Games: 7944\n",
      "Num Frames: 2200576\n",
      "FPS: 452\n",
      "ETA: 1:43:00\n",
      "SMA Length: 375.53\n",
      "SMA Reward: 9.08\n",
      "SMA Entropy: 0.9062887889146805\n",
      "SMA Loss: 0.007733441679738462\n",
      "SMA PG Loss: -0.017628180377651004\n",
      "SMA V Loss: 0.06884901938959956\n",
      "SMA Intrinsic Reward: 0.06557683065533639\n",
      "SMA ICM Loss: 0.42411012068390846\n",
      "Max reward: 28.0\n",
      "---------- 2175 / 4882 ----------\n",
      "Num Games: 8009\n",
      "Num Frames: 2226176\n",
      "FPS: 452\n",
      "ETA: 1:42:03\n",
      "SMA Length: 375.825\n",
      "SMA Reward: 8.95\n",
      "SMA Entropy: 0.9057158169150352\n",
      "SMA Loss: 0.009306481848470867\n",
      "SMA PG Loss: -0.015748617991339416\n",
      "SMA V Loss: 0.0682245154120028\n",
      "SMA Intrinsic Reward: 0.06535032659769058\n",
      "SMA ICM Loss: 0.42374843686819075\n",
      "Max reward: 28.0\n",
      "---------- 2200 / 4882 ----------\n",
      "Num Games: 8081\n",
      "Num Frames: 2251776\n",
      "FPS: 453\n",
      "ETA: 1:41:06\n",
      "SMA Length: 377.41\n",
      "SMA Reward: 8.93\n",
      "SMA Entropy: 0.9042754077911377\n",
      "SMA Loss: 0.009337828885763884\n",
      "SMA PG Loss: -0.01571279737399891\n",
      "SMA V Loss: 0.06818676024675369\n",
      "SMA Intrinsic Reward: 0.06489562002941966\n",
      "SMA ICM Loss: 0.42219532519578934\n",
      "Max reward: 28.0\n",
      "---------- 2225 / 4882 ----------\n",
      "Num Games: 8154\n",
      "Num Frames: 2277376\n",
      "FPS: 453\n",
      "ETA: 1:40:09\n",
      "SMA Length: 380.22\n",
      "SMA Reward: 9.01\n",
      "SMA Entropy: 0.9053853008151055\n",
      "SMA Loss: 0.008715227427892387\n",
      "SMA PG Loss: -0.01639992600074038\n",
      "SMA V Loss: 0.06833801243454218\n",
      "SMA Intrinsic Reward: 0.06470082195475697\n",
      "SMA ICM Loss: 0.42014584586024284\n",
      "Max reward: 28.0\n",
      "---------- 2250 / 4882 ----------\n",
      "Num Games: 8225\n",
      "Num Frames: 2302976\n",
      "FPS: 453\n",
      "ETA: 1:39:11\n",
      "SMA Length: 363.035\n",
      "SMA Reward: 8.515\n",
      "SMA Entropy: 0.9084270253777504\n",
      "SMA Loss: 0.011615884364582598\n",
      "SMA PG Loss: -0.01362238591304049\n",
      "SMA V Loss: 0.06864508047699928\n",
      "SMA Intrinsic Reward: 0.06505762403830886\n",
      "SMA ICM Loss: 0.41746012508869174\n",
      "Max reward: 28.0\n",
      "---------- 2275 / 4882 ----------\n",
      "Num Games: 8297\n",
      "Num Frames: 2328576\n",
      "FPS: 453\n",
      "ETA: 1:38:14\n",
      "SMA Length: 368.27\n",
      "SMA Reward: 8.675\n",
      "SMA Entropy: 0.9126604709029198\n",
      "SMA Loss: 0.010349201723001897\n",
      "SMA PG Loss: -0.014810569875407964\n",
      "SMA V Loss: 0.06857275212183594\n",
      "SMA Intrinsic Reward: 0.06502936020493508\n",
      "SMA ICM Loss: 0.417460590004921\n",
      "Max reward: 28.0\n",
      "---------- 2300 / 4882 ----------\n",
      "Num Games: 8363\n",
      "Num Frames: 2354176\n",
      "FPS: 453\n",
      "ETA: 1:37:16\n",
      "SMA Length: 381.365\n",
      "SMA Reward: 9.11\n",
      "SMA Entropy: 0.9127581164240837\n",
      "SMA Loss: 0.009219673252664507\n",
      "SMA PG Loss: -0.016342273100744934\n",
      "SMA V Loss: 0.06937905453145504\n",
      "SMA Intrinsic Reward: 0.06508529284968972\n",
      "SMA ICM Loss: 0.41186570569872855\n",
      "Max reward: 32.0\n",
      "---------- 2325 / 4882 ----------\n",
      "Num Games: 8428\n",
      "Num Frames: 2379776\n",
      "FPS: 453\n",
      "ETA: 1:36:19\n",
      "SMA Length: 395.095\n",
      "SMA Reward: 10.005\n",
      "SMA Entropy: 0.9032150492072105\n",
      "SMA Loss: 0.00939034515991807\n",
      "SMA PG Loss: -0.017011053045280278\n",
      "SMA V Loss: 0.07086709685623646\n",
      "SMA Intrinsic Reward: 0.06450316168367863\n",
      "SMA ICM Loss: 0.4041599409282208\n",
      "Max reward: 32.0\n",
      "---------- 2350 / 4882 ----------\n",
      "Num Games: 8496\n",
      "Num Frames: 2405376\n",
      "FPS: 453\n",
      "ETA: 1:35:21\n",
      "SMA Length: 400.14\n",
      "SMA Reward: 10.35\n",
      "SMA Entropy: 0.8984864565730095\n",
      "SMA Loss: 0.009224763016682118\n",
      "SMA PG Loss: -0.01745630877558142\n",
      "SMA V Loss: 0.07133187206462026\n",
      "SMA Intrinsic Reward: 0.06385483797639609\n",
      "SMA ICM Loss: 0.3997526586055756\n",
      "Max reward: 32.0\n",
      "---------- 2375 / 4882 ----------\n",
      "Num Games: 8563\n",
      "Num Frames: 2430976\n",
      "FPS: 453\n",
      "ETA: 1:34:24\n",
      "SMA Length: 397.825\n",
      "SMA Reward: 10.14\n",
      "SMA Entropy: 0.8972345739603043\n",
      "SMA Loss: 0.008435116086620837\n",
      "SMA PG Loss: -0.01823067430406809\n",
      "SMA V Loss: 0.07127627167850732\n",
      "SMA Intrinsic Reward: 0.06364112008363008\n",
      "SMA ICM Loss: 0.395760013461113\n",
      "Max reward: 32.0\n",
      "---------- 2400 / 4882 ----------\n",
      "Num Games: 8631\n",
      "Num Frames: 2456576\n",
      "FPS: 453\n",
      "ETA: 1:33:26\n",
      "SMA Length: 394.93\n",
      "SMA Reward: 9.595\n",
      "SMA Entropy: 0.8988816976547241\n",
      "SMA Loss: 0.010072916217613965\n",
      "SMA PG Loss: -0.016504897573031484\n",
      "SMA V Loss: 0.07113326080143452\n",
      "SMA Intrinsic Reward: 0.06338204799219965\n",
      "SMA ICM Loss: 0.39315537720918653\n",
      "Max reward: 32.0\n",
      "---------- 2425 / 4882 ----------\n",
      "Num Games: 8713\n",
      "Num Frames: 2482176\n",
      "FPS: 453\n",
      "ETA: 1:32:30\n",
      "SMA Length: 364.21\n",
      "SMA Reward: 8.265\n",
      "SMA Entropy: 0.9035425880551338\n",
      "SMA Loss: 0.010693698350805789\n",
      "SMA PG Loss: -0.01574500715127215\n",
      "SMA V Loss: 0.07094826202839613\n",
      "SMA Intrinsic Reward: 0.06313596719875932\n",
      "SMA ICM Loss: 0.3952028261125088\n",
      "Max reward: 32.0\n",
      "---------- 2450 / 4882 ----------\n",
      "Num Games: 8786\n",
      "Num Frames: 2507776\n",
      "FPS: 453\n",
      "ETA: 1:31:33\n",
      "SMA Length: 350.91\n",
      "SMA Reward: 8.1\n",
      "SMA Entropy: 0.9013758394122123\n",
      "SMA Loss: 0.010106156223919242\n",
      "SMA PG Loss: -0.01649868818698451\n",
      "SMA V Loss: 0.07123720500618219\n",
      "SMA Intrinsic Reward: 0.062305626776069406\n",
      "SMA ICM Loss: 0.39417218044400215\n",
      "Max reward: 32.0\n",
      "---------- 2475 / 4882 ----------\n",
      "Num Games: 8857\n",
      "Num Frames: 2533376\n",
      "FPS: 453\n",
      "ETA: 1:30:35\n",
      "SMA Length: 355.355\n",
      "SMA Reward: 8.545\n",
      "SMA Entropy: 0.8975157383084297\n",
      "SMA Loss: 0.008508977883029728\n",
      "SMA PG Loss: -0.01782517429208383\n",
      "SMA V Loss: 0.07061861846596003\n",
      "SMA Intrinsic Reward: 0.06175026636570692\n",
      "SMA ICM Loss: 0.39082306414842605\n",
      "Max reward: 32.0\n",
      "---------- 2500 / 4882 ----------\n",
      "Num Games: 8928\n",
      "Num Frames: 2558976\n",
      "FPS: 453\n",
      "ETA: 1:29:38\n",
      "SMA Length: 360.84\n",
      "SMA Reward: 8.62\n",
      "SMA Entropy: 0.9006503763794899\n",
      "SMA Loss: 0.00878849366446957\n",
      "SMA PG Loss: -0.017544572737533598\n",
      "SMA V Loss: 0.07067913979291916\n",
      "SMA Intrinsic Reward: 0.061524748988449576\n",
      "SMA ICM Loss: 0.39143539309501646\n",
      "Max reward: 32.0\n",
      "---------- 2525 / 4882 ----------\n",
      "Num Games: 9007\n",
      "Num Frames: 2584576\n",
      "FPS: 453\n",
      "ETA: 1:28:42\n",
      "SMA Length: 358.46\n",
      "SMA Reward: 8.395\n",
      "SMA Entropy: 0.9166870364546775\n",
      "SMA Loss: 0.008276248828042298\n",
      "SMA PG Loss: -0.017538821045309304\n",
      "SMA V Loss: 0.0699638800881803\n",
      "SMA Intrinsic Reward: 0.06161153838038445\n",
      "SMA ICM Loss: 0.40442387342453\n",
      "Max reward: 32.0\n",
      "---------- 2550 / 4882 ----------\n",
      "Num Games: 9080\n",
      "Num Frames: 2610176\n",
      "FPS: 453\n",
      "ETA: 1:27:45\n",
      "SMA Length: 363.76\n",
      "SMA Reward: 8.49\n",
      "SMA Entropy: 0.9267197421193123\n",
      "SMA Loss: 0.008723114100284875\n",
      "SMA PG Loss: -0.016862489911727608\n",
      "SMA V Loss: 0.06970560260117054\n",
      "SMA Intrinsic Reward: 0.06128584837540984\n",
      "SMA ICM Loss: 0.4159113557636738\n",
      "Max reward: 32.0\n",
      "---------- 2575 / 4882 ----------\n",
      "Num Games: 9153\n",
      "Num Frames: 2635776\n",
      "FPS: 453\n",
      "ETA: 1:26:48\n",
      "SMA Length: 359.89\n",
      "SMA Reward: 8.31\n",
      "SMA Entropy: 0.9293562424182892\n",
      "SMA Loss: 0.009297466315329074\n",
      "SMA PG Loss: -0.016813442977145314\n",
      "SMA V Loss: 0.07080894324928522\n",
      "SMA Intrinsic Reward: 0.06075529167428613\n",
      "SMA ICM Loss: 0.42237063109874723\n",
      "Max reward: 32.0\n",
      "---------- 2600 / 4882 ----------\n",
      "Num Games: 9222\n",
      "Num Frames: 2661376\n",
      "FPS: 453\n",
      "ETA: 1:25:51\n",
      "SMA Length: 370.7\n",
      "SMA Reward: 8.455\n",
      "SMA Entropy: 0.9365859305858613\n",
      "SMA Loss: 0.008655242188833654\n",
      "SMA PG Loss: -0.017053969651460648\n",
      "SMA V Loss: 0.07015014205127955\n",
      "SMA Intrinsic Reward: 0.060660580303519965\n",
      "SMA ICM Loss: 0.4306993645429611\n",
      "Max reward: 32.0\n",
      "---------- 2625 / 4882 ----------\n",
      "Num Games: 9300\n",
      "Num Frames: 2686976\n",
      "FPS: 453\n",
      "ETA: 1:24:54\n",
      "SMA Length: 356.04\n",
      "SMA Reward: 7.865\n",
      "SMA Entropy: 0.9385894224047661\n",
      "SMA Loss: 0.007404162115417421\n",
      "SMA PG Loss: -0.018230544589459895\n",
      "SMA V Loss: 0.07004120163619518\n",
      "SMA Intrinsic Reward: 0.0606477677822113\n",
      "SMA ICM Loss: 0.43186209559440614\n",
      "Max reward: 32.0\n",
      "---------- 2650 / 4882 ----------\n",
      "Num Games: 9364\n",
      "Num Frames: 2712576\n",
      "FPS: 454\n",
      "ETA: 1:23:57\n",
      "SMA Length: 373.16\n",
      "SMA Reward: 8.71\n",
      "SMA Entropy: 0.9426168364286422\n",
      "SMA Loss: 0.00716585626360029\n",
      "SMA PG Loss: -0.01793086198391393\n",
      "SMA V Loss: 0.06904577299952507\n",
      "SMA Intrinsic Reward: 0.06037614354863763\n",
      "SMA ICM Loss: 0.4357658965885639\n",
      "Max reward: 32.0\n",
      "---------- 2675 / 4882 ----------\n",
      "Num Games: 9437\n",
      "Num Frames: 2738176\n",
      "FPS: 454\n",
      "ETA: 1:23:00\n",
      "SMA Length: 377.25\n",
      "SMA Reward: 9.015\n",
      "SMA Entropy: 0.9501866719126701\n",
      "SMA Loss: 0.008977362224832176\n",
      "SMA PG Loss: -0.016371455541811884\n",
      "SMA V Loss: 0.06970136879011989\n",
      "SMA Intrinsic Reward: 0.06025621684268117\n",
      "SMA ICM Loss: 0.442773594558239\n",
      "Max reward: 32.0\n",
      "---------- 2700 / 4882 ----------\n",
      "Num Games: 9506\n",
      "Num Frames: 2763776\n",
      "FPS: 454\n",
      "ETA: 1:22:04\n",
      "SMA Length: 388.83\n",
      "SMA Reward: 9.45\n",
      "SMA Entropy: 0.9522975659370423\n",
      "SMA Loss: 0.009098178115673363\n",
      "SMA PG Loss: -0.016165805817581713\n",
      "SMA V Loss: 0.06957391889765858\n",
      "SMA Intrinsic Reward: 0.05963874276727438\n",
      "SMA ICM Loss: 0.44813443630933764\n",
      "Max reward: 32.0\n",
      "---------- 2725 / 4882 ----------\n",
      "Num Games: 9574\n",
      "Num Frames: 2789376\n",
      "FPS: 454\n",
      "ETA: 1:21:07\n",
      "SMA Length: 378.36\n",
      "SMA Reward: 8.945\n",
      "SMA Entropy: 0.9473975273966789\n",
      "SMA Loss: 0.01106395204551518\n",
      "SMA PG Loss: -0.014465301044983789\n",
      "SMA V Loss: 0.07000645654276014\n",
      "SMA Intrinsic Reward: 0.059339507464319464\n",
      "SMA ICM Loss: 0.44275639951229095\n",
      "Max reward: 32.0\n",
      "---------- 2750 / 4882 ----------\n",
      "Num Games: 9648\n",
      "Num Frames: 2814976\n",
      "FPS: 454\n",
      "ETA: 1:20:10\n",
      "SMA Length: 378.25\n",
      "SMA Reward: 8.9\n",
      "SMA Entropy: 0.9470537069439888\n",
      "SMA Loss: 0.011375030307099222\n",
      "SMA PG Loss: -0.014405469034099951\n",
      "SMA V Loss: 0.07050207260996104\n",
      "SMA Intrinsic Reward: 0.05908691788092255\n",
      "SMA ICM Loss: 0.44030448630452157\n",
      "Max reward: 32.0\n",
      "---------- 2775 / 4882 ----------\n",
      "Num Games: 9714\n",
      "Num Frames: 2840576\n",
      "FPS: 454\n",
      "ETA: 1:19:14\n",
      "SMA Length: 381.905\n",
      "SMA Reward: 9.14\n",
      "SMA Entropy: 0.9467580097913743\n",
      "SMA Loss: 0.011406884025782348\n",
      "SMA PG Loss: -0.014283224045066163\n",
      "SMA V Loss: 0.07031537609174848\n",
      "SMA Intrinsic Reward: 0.05859495963901282\n",
      "SMA ICM Loss: 0.43810437053442003\n",
      "Max reward: 32.0\n",
      "---------- 2800 / 4882 ----------\n",
      "Num Games: 9783\n",
      "Num Frames: 2866176\n",
      "FPS: 454\n",
      "ETA: 1:18:17\n",
      "SMA Length: 382.085\n",
      "SMA Reward: 9.145\n",
      "SMA Entropy: 0.9385468715429306\n",
      "SMA Loss: 0.010644857743754984\n",
      "SMA PG Loss: -0.015352872548392042\n",
      "SMA V Loss: 0.07076639773324132\n",
      "SMA Intrinsic Reward: 0.05744307160377502\n",
      "SMA ICM Loss: 0.43428550332784654\n",
      "Max reward: 32.0\n",
      "---------- 2825 / 4882 ----------\n",
      "Num Games: 9851\n",
      "Num Frames: 2891776\n",
      "FPS: 454\n",
      "ETA: 1:17:20\n",
      "SMA Length: 392.18\n",
      "SMA Reward: 9.49\n",
      "SMA Entropy: 0.9368446835875511\n",
      "SMA Loss: 0.010970946191810072\n",
      "SMA PG Loss: -0.014993791355518624\n",
      "SMA V Loss: 0.0706663685105741\n",
      "SMA Intrinsic Reward: 0.0565983422100544\n",
      "SMA ICM Loss: 0.43540294632315635\n",
      "Max reward: 32.0\n",
      "---------- 2850 / 4882 ----------\n",
      "Num Games: 9921\n",
      "Num Frames: 2917376\n",
      "FPS: 454\n",
      "ETA: 1:16:23\n",
      "SMA Length: 384.245\n",
      "SMA Reward: 9.2\n",
      "SMA Entropy: 0.9390787848830223\n",
      "SMA Loss: 0.010969870835542678\n",
      "SMA PG Loss: -0.01508040409651585\n",
      "SMA V Loss: 0.07088212532922626\n",
      "SMA Intrinsic Reward: 0.056252177692949774\n",
      "SMA ICM Loss: 0.43442908599972724\n",
      "Max reward: 32.0\n",
      "---------- 2875 / 4882 ----------\n",
      "Num Games: 9987\n",
      "Num Frames: 2942976\n",
      "FPS: 454\n",
      "ETA: 1:15:27\n",
      "SMA Length: 385.745\n",
      "SMA Reward: 9.005\n",
      "SMA Entropy: 0.9369224897027015\n",
      "SMA Loss: 0.012050803722813726\n",
      "SMA PG Loss: -0.014077623261837289\n",
      "SMA V Loss: 0.07099530348554253\n",
      "SMA Intrinsic Reward: 0.055736065581440924\n",
      "SMA ICM Loss: 0.4283209981024265\n",
      "Max reward: 32.0\n",
      "---------- 2900 / 4882 ----------\n",
      "Num Games: 10054\n",
      "Num Frames: 2968576\n",
      "FPS: 454\n",
      "ETA: 1:14:30\n",
      "SMA Length: 390.75\n",
      "SMA Reward: 9.295\n",
      "SMA Entropy: 0.9315734073519707\n",
      "SMA Loss: 0.012427100911736488\n",
      "SMA PG Loss: -0.01333321991027333\n",
      "SMA V Loss: 0.07015210954472423\n",
      "SMA Intrinsic Reward: 0.05538481263443828\n",
      "SMA ICM Loss: 0.4221558305621147\n",
      "Max reward: 32.0\n",
      "---------- 2925 / 4882 ----------\n",
      "Num Games: 10124\n",
      "Num Frames: 2994176\n",
      "FPS: 454\n",
      "ETA: 1:13:34\n",
      "SMA Length: 392.105\n",
      "SMA Reward: 9.455\n",
      "SMA Entropy: 0.9369999465346336\n",
      "SMA Loss: 0.011459986488334835\n",
      "SMA PG Loss: -0.01429989334428683\n",
      "SMA V Loss: 0.07025975810363888\n",
      "SMA Intrinsic Reward: 0.05511929962784052\n",
      "SMA ICM Loss: 0.4245204319059849\n",
      "Max reward: 32.0\n",
      "---------- 2950 / 4882 ----------\n",
      "Num Games: 10212\n",
      "Num Frames: 3019776\n",
      "FPS: 454\n",
      "ETA: 1:12:39\n",
      "SMA Length: 348.885\n",
      "SMA Reward: 7.795\n",
      "SMA Entropy: 0.9425631281733513\n",
      "SMA Loss: 0.011366599430330098\n",
      "SMA PG Loss: -0.014093867056071758\n",
      "SMA V Loss: 0.06977219507098198\n",
      "SMA Intrinsic Reward: 0.055251657646149394\n",
      "SMA ICM Loss: 0.4244361947476864\n",
      "Max reward: 32.0\n",
      "---------- 2975 / 4882 ----------\n",
      "Num Games: 10283\n",
      "Num Frames: 3045376\n",
      "FPS: 454\n",
      "ETA: 1:11:42\n",
      "SMA Length: 341.34\n",
      "SMA Reward: 7.48\n",
      "SMA Entropy: 0.9491110676527024\n",
      "SMA Loss: 0.010744177778251469\n",
      "SMA PG Loss: -0.014313473792281001\n",
      "SMA V Loss: 0.06909752393141388\n",
      "SMA Intrinsic Reward: 0.055240061208605765\n",
      "SMA ICM Loss: 0.4310720017552376\n",
      "Max reward: 32.0\n",
      "---------- 3000 / 4882 ----------\n",
      "Num Games: 10355\n",
      "Num Frames: 3070976\n",
      "FPS: 454\n",
      "ETA: 1:10:46\n",
      "SMA Length: 347.41\n",
      "SMA Reward: 7.685\n",
      "SMA Entropy: 0.9573658800125122\n",
      "SMA Loss: 0.01121965556871146\n",
      "SMA PG Loss: -0.013518286866601557\n",
      "SMA V Loss: 0.06862320212647319\n",
      "SMA Intrinsic Reward: 0.0556304251588881\n",
      "SMA ICM Loss: 0.4349265971779823\n",
      "Max reward: 32.0\n",
      "---------- 3025 / 4882 ----------\n",
      "Num Games: 10429\n",
      "Num Frames: 3096576\n",
      "FPS: 454\n",
      "ETA: 1:09:49\n",
      "SMA Length: 375.945\n",
      "SMA Reward: 8.74\n",
      "SMA Entropy: 0.9626857894659042\n",
      "SMA Loss: 0.011709500537253916\n",
      "SMA PG Loss: -0.01283928623655811\n",
      "SMA V Loss: 0.06835128901526331\n",
      "SMA Intrinsic Reward: 0.05585021400824189\n",
      "SMA ICM Loss: 0.4361675271391869\n",
      "Max reward: 32.0\n",
      "---------- 3050 / 4882 ----------\n",
      "Num Games: 10496\n",
      "Num Frames: 3122176\n",
      "FPS: 454\n",
      "ETA: 1:08:53\n",
      "SMA Length: 375.11\n",
      "SMA Reward: 8.69\n",
      "SMA Entropy: 0.9652542424201965\n",
      "SMA Loss: 0.011569179687649011\n",
      "SMA PG Loss: -0.013630915679968894\n",
      "SMA V Loss: 0.06970527529716491\n",
      "SMA Intrinsic Reward: 0.055739855039864776\n",
      "SMA ICM Loss: 0.4407126675546169\n",
      "Max reward: 32.0\n",
      "---------- 3075 / 4882 ----------\n",
      "Num Games: 10561\n",
      "Num Frames: 3147776\n",
      "FPS: 454\n",
      "ETA: 1:07:56\n",
      "SMA Length: 390.885\n",
      "SMA Reward: 9.09\n",
      "SMA Entropy: 0.9697760021686554\n",
      "SMA Loss: 0.009907878441736103\n",
      "SMA PG Loss: -0.014992265300825237\n",
      "SMA V Loss: 0.06919580720365047\n",
      "SMA Intrinsic Reward: 0.05564936561509967\n",
      "SMA ICM Loss: 0.4476263020932674\n",
      "Max reward: 32.0\n",
      "---------- 3100 / 4882 ----------\n",
      "Num Games: 10629\n",
      "Num Frames: 3173376\n",
      "FPS: 454\n",
      "ETA: 1:07:00\n",
      "SMA Length: 392.28\n",
      "SMA Reward: 9.26\n",
      "SMA Entropy: 0.9784350037574768\n",
      "SMA Loss: 0.010605702614411712\n",
      "SMA PG Loss: -0.014816753638442606\n",
      "SMA V Loss: 0.07041361229494214\n",
      "SMA Intrinsic Reward: 0.055664333552122115\n",
      "SMA ICM Loss: 0.4550894847512245\n",
      "Max reward: 32.0\n",
      "---------- 3125 / 4882 ----------\n",
      "Num Games: 10703\n",
      "Num Frames: 3198976\n",
      "FPS: 454\n",
      "ETA: 1:06:03\n",
      "SMA Length: 383.505\n",
      "SMA Reward: 9.01\n",
      "SMA Entropy: 0.9781710591912269\n",
      "SMA Loss: 0.011443087114021182\n",
      "SMA PG Loss: -0.014094723809976131\n",
      "SMA V Loss: 0.07063904291018844\n",
      "SMA Intrinsic Reward: 0.05532984854653478\n",
      "SMA ICM Loss: 0.45372453913092614\n",
      "Max reward: 32.0\n",
      "---------- 3150 / 4882 ----------\n",
      "Num Games: 10763\n",
      "Num Frames: 3224576\n",
      "FPS: 454\n",
      "ETA: 1:05:06\n",
      "SMA Length: 389.075\n",
      "SMA Reward: 9.395\n",
      "SMA Entropy: 0.9758356857299805\n",
      "SMA Loss: 0.012436745790764689\n",
      "SMA PG Loss: -0.013447905897628516\n",
      "SMA V Loss: 0.0712860170006752\n",
      "SMA Intrinsic Reward: 0.0544832456111908\n",
      "SMA ICM Loss: 0.45270051807165146\n",
      "Max reward: 32.0\n",
      "---------- 3175 / 4882 ----------\n",
      "Num Games: 10829\n",
      "Num Frames: 3250176\n",
      "FPS: 454\n",
      "ETA: 1:04:10\n",
      "SMA Length: 397.895\n",
      "SMA Reward: 9.6\n",
      "SMA Entropy: 0.9702609562873841\n",
      "SMA Loss: 0.010960835856385529\n",
      "SMA PG Loss: -0.01530557248275727\n",
      "SMA V Loss: 0.07193803573027253\n",
      "SMA Intrinsic Reward: 0.05370312798768282\n",
      "SMA ICM Loss: 0.4434671929478645\n",
      "Max reward: 32.0\n",
      "---------- 3200 / 4882 ----------\n",
      "Num Games: 10901\n",
      "Num Frames: 3275776\n",
      "FPS: 454\n",
      "ETA: 1:03:14\n",
      "SMA Length: 399.845\n",
      "SMA Reward: 9.635\n",
      "SMA Entropy: 0.9631718572974205\n",
      "SMA Loss: 0.010426370580680668\n",
      "SMA PG Loss: -0.016532175396569072\n",
      "SMA V Loss: 0.0731805288232863\n",
      "SMA Intrinsic Reward: 0.05278622644022107\n",
      "SMA ICM Loss: 0.43556390568614006\n",
      "Max reward: 32.0\n",
      "---------- 3225 / 4882 ----------\n",
      "Num Games: 10965\n",
      "Num Frames: 3301376\n",
      "FPS: 454\n",
      "ETA: 1:02:17\n",
      "SMA Length: 399.275\n",
      "SMA Reward: 9.79\n",
      "SMA Entropy: 0.9527277013659478\n",
      "SMA Loss: 0.009869861220940947\n",
      "SMA PG Loss: -0.017321292129345238\n",
      "SMA V Loss: 0.07343686036765576\n",
      "SMA Intrinsic Reward: 0.051755142267793416\n",
      "SMA ICM Loss: 0.4259661562740803\n",
      "Max reward: 32.0\n",
      "---------- 3250 / 4882 ----------\n",
      "Num Games: 11031\n",
      "Num Frames: 3326976\n",
      "FPS: 454\n",
      "ETA: 1:01:21\n",
      "SMA Length: 394.015\n",
      "SMA Reward: 9.58\n",
      "SMA Entropy: 0.9462047630548477\n",
      "SMA Loss: 0.009725537919439375\n",
      "SMA PG Loss: -0.017437663497403263\n",
      "SMA V Loss: 0.07325049759820104\n",
      "SMA Intrinsic Reward: 0.05116260141134262\n",
      "SMA ICM Loss: 0.41529194712638856\n",
      "Max reward: 32.0\n",
      "---------- 3275 / 4882 ----------\n",
      "Num Games: 11102\n",
      "Num Frames: 3352576\n",
      "FPS: 454\n",
      "ETA: 1:00:24\n",
      "SMA Length: 395.61\n",
      "SMA Reward: 9.845\n",
      "SMA Entropy: 0.9372000983357429\n",
      "SMA Loss: 0.009848770000971854\n",
      "SMA PG Loss: -0.017798617822118102\n",
      "SMA V Loss: 0.07403877720236779\n",
      "SMA Intrinsic Reward: 0.05037309912964702\n",
      "SMA ICM Loss: 0.40482073083519937\n",
      "Max reward: 32.0\n",
      "---------- 3300 / 4882 ----------\n",
      "Num Games: 11170\n",
      "Num Frames: 3378176\n",
      "FPS: 454\n",
      "ETA: 0:59:28\n",
      "SMA Length: 390.635\n",
      "SMA Reward: 9.525\n",
      "SMA Entropy: 0.9296617150306702\n",
      "SMA Loss: 0.010402155257761479\n",
      "SMA PG Loss: -0.017461823287885637\n",
      "SMA V Loss: 0.0743211911059916\n",
      "SMA Intrinsic Reward: 0.0497266780026257\n",
      "SMA ICM Loss: 0.39403740391135217\n",
      "Max reward: 32.0\n",
      "---------- 3325 / 4882 ----------\n",
      "Num Games: 11236\n",
      "Num Frames: 3403776\n",
      "FPS: 454\n",
      "ETA: 0:58:31\n",
      "SMA Length: 389.88\n",
      "SMA Reward: 9.46\n",
      "SMA Entropy: 0.9258184507489204\n",
      "SMA Loss: 0.010017808694392442\n",
      "SMA PG Loss: -0.01791024733101949\n",
      "SMA V Loss: 0.07437248066067696\n",
      "SMA Intrinsic Reward: 0.048976327795535325\n",
      "SMA ICM Loss: 0.3912724584341049\n",
      "Max reward: 32.0\n",
      "---------- 3350 / 4882 ----------\n",
      "Num Games: 11305\n",
      "Num Frames: 3429376\n",
      "FPS: 454\n",
      "ETA: 0:57:35\n",
      "SMA Length: 391.46\n",
      "SMA Reward: 9.32\n",
      "SMA Entropy: 0.9209721517562867\n",
      "SMA Loss: 0.008675270061939955\n",
      "SMA PG Loss: -0.018953842262271793\n",
      "SMA V Loss: 0.0736776672489941\n",
      "SMA Intrinsic Reward: 0.04844313060864806\n",
      "SMA ICM Loss: 0.3887874276936054\n",
      "Max reward: 32.0\n",
      "---------- 3375 / 4882 ----------\n",
      "Num Games: 11366\n",
      "Num Frames: 3454976\n",
      "FPS: 454\n",
      "ETA: 0:56:38\n",
      "SMA Length: 399.745\n",
      "SMA Reward: 9.545\n",
      "SMA Entropy: 0.9200135385990142\n",
      "SMA Loss: 0.009812064110301435\n",
      "SMA PG Loss: -0.017887906841933726\n",
      "SMA V Loss: 0.07380021231248975\n",
      "SMA Intrinsic Reward: 0.048165009468793867\n",
      "SMA ICM Loss: 0.3883632729947567\n",
      "Max reward: 32.0\n",
      "---------- 3400 / 4882 ----------\n",
      "Num Games: 11426\n",
      "Num Frames: 3480576\n",
      "FPS: 454\n",
      "ETA: 0:55:41\n",
      "SMA Length: 414.69\n",
      "SMA Reward: 10.07\n",
      "SMA Entropy: 0.9169063967466354\n",
      "SMA Loss: 0.011103330096229911\n",
      "SMA PG Loss: -0.017044387618079783\n",
      "SMA V Loss: 0.07463356306776404\n",
      "SMA Intrinsic Reward: 0.047781966477632526\n",
      "SMA ICM Loss: 0.38612441897392275\n",
      "Max reward: 32.0\n",
      "---------- 3425 / 4882 ----------\n",
      "Num Games: 11490\n",
      "Num Frames: 3506176\n",
      "FPS: 454\n",
      "ETA: 0:54:45\n",
      "SMA Length: 432.26\n",
      "SMA Reward: 10.815\n",
      "SMA Entropy: 0.9219265034794808\n",
      "SMA Loss: 0.012575990953482687\n",
      "SMA PG Loss: -0.016025113300420345\n",
      "SMA V Loss: 0.07564073828980326\n",
      "SMA Intrinsic Reward: 0.04760519850999117\n",
      "SMA ICM Loss: 0.39020583108067514\n",
      "Max reward: 32.0\n",
      "---------- 3450 / 4882 ----------\n",
      "Num Games: 11558\n",
      "Num Frames: 3531776\n",
      "FPS: 454\n",
      "ETA: 0:53:48\n",
      "SMA Length: 412.715\n",
      "SMA Reward: 10.115\n",
      "SMA Entropy: 0.9262714120745659\n",
      "SMA Loss: 0.013608596012927592\n",
      "SMA PG Loss: -0.014557453996967524\n",
      "SMA V Loss: 0.07485752796754241\n",
      "SMA Intrinsic Reward: 0.046984493862837554\n",
      "SMA ICM Loss: 0.3982606135308743\n",
      "Max reward: 32.0\n",
      "---------- 3475 / 4882 ----------\n",
      "Num Games: 11622\n",
      "Num Frames: 3557376\n",
      "FPS: 454\n",
      "ETA: 0:52:52\n",
      "SMA Length: 403.665\n",
      "SMA Reward: 9.935\n",
      "SMA Entropy: 0.9267087268829346\n",
      "SMA Loss: 0.013332094568759202\n",
      "SMA PG Loss: -0.014789135868195444\n",
      "SMA V Loss: 0.07477663500234484\n",
      "SMA Intrinsic Reward: 0.0466919076256454\n",
      "SMA ICM Loss: 0.3996886284649372\n",
      "Max reward: 32.0\n",
      "---------- 3500 / 4882 ----------\n",
      "Num Games: 11694\n",
      "Num Frames: 3582976\n",
      "FPS: 454\n",
      "ETA: 0:51:55\n",
      "SMA Length: 391.445\n",
      "SMA Reward: 9.38\n",
      "SMA Entropy: 0.9265588855743409\n",
      "SMA Loss: 0.012315577873960138\n",
      "SMA PG Loss: -0.015610355990938843\n",
      "SMA V Loss: 0.07438304495066404\n",
      "SMA Intrinsic Reward: 0.04623323233798146\n",
      "SMA ICM Loss: 0.4019772718846798\n",
      "Max reward: 32.0\n",
      "---------- 3525 / 4882 ----------\n",
      "Num Games: 11757\n",
      "Num Frames: 3608576\n",
      "FPS: 454\n",
      "ETA: 0:50:59\n",
      "SMA Length: 396.78\n",
      "SMA Reward: 9.835\n",
      "SMA Entropy: 0.9269887867569924\n",
      "SMA Loss: 0.012871010615490376\n",
      "SMA PG Loss: -0.015431179946754128\n",
      "SMA V Loss: 0.07514415642246604\n",
      "SMA Intrinsic Reward: 0.04598415400832891\n",
      "SMA ICM Loss: 0.4017216663062573\n",
      "Max reward: 32.0\n",
      "---------- 3550 / 4882 ----------\n",
      "Num Games: 11818\n",
      "Num Frames: 3634176\n",
      "FPS: 454\n",
      "ETA: 0:50:02\n",
      "SMA Length: 408.84\n",
      "SMA Reward: 10.27\n",
      "SMA Entropy: 0.9251144537329674\n",
      "SMA Loss: 0.014489551475271582\n",
      "SMA PG Loss: -0.014863533473107964\n",
      "SMA V Loss: 0.07720845837146044\n",
      "SMA Intrinsic Reward: 0.045662041604518894\n",
      "SMA ICM Loss: 0.4015815916657448\n",
      "Max reward: 32.0\n",
      "---------- 3575 / 4882 ----------\n",
      "Num Games: 11881\n",
      "Num Frames: 3659776\n",
      "FPS: 454\n",
      "ETA: 0:49:06\n",
      "SMA Length: 416.695\n",
      "SMA Reward: 10.62\n",
      "SMA Entropy: 0.9265000492334365\n",
      "SMA Loss: 0.016252810801379382\n",
      "SMA PG Loss: -0.013563665938563644\n",
      "SMA V Loss: 0.07816295379772782\n",
      "SMA Intrinsic Reward: 0.045366171449422836\n",
      "SMA ICM Loss: 0.40167282074689864\n",
      "Max reward: 32.0\n",
      "---------- 3600 / 4882 ----------\n",
      "Num Games: 11944\n",
      "Num Frames: 3685376\n",
      "FPS: 454\n",
      "ETA: 0:48:09\n",
      "SMA Length: 431.84\n",
      "SMA Reward: 11.0\n",
      "SMA Entropy: 0.9342795288562775\n",
      "SMA Loss: 0.015389656033366918\n",
      "SMA PG Loss: -0.013841573549434542\n",
      "SMA V Loss: 0.07714804911985994\n",
      "SMA Intrinsic Reward: 0.045244562756270174\n",
      "SMA ICM Loss: 0.408663250207901\n",
      "Max reward: 32.0\n",
      "---------- 3625 / 4882 ----------\n",
      "Num Games: 12012\n",
      "Num Frames: 3710976\n",
      "FPS: 454\n",
      "ETA: 0:47:13\n",
      "SMA Length: 414.82\n",
      "SMA Reward: 10.23\n",
      "SMA Entropy: 0.936731379032135\n",
      "SMA Loss: 0.013014695192687213\n",
      "SMA PG Loss: -0.015683218338526785\n",
      "SMA V Loss: 0.07613045409321785\n",
      "SMA Intrinsic Reward: 0.045048394985496995\n",
      "SMA ICM Loss: 0.41126584812998773\n",
      "Max reward: 32.0\n",
      "---------- 3650 / 4882 ----------\n",
      "Num Games: 12070\n",
      "Num Frames: 3736576\n",
      "FPS: 454\n",
      "ETA: 0:46:16\n",
      "SMA Length: 414.585\n",
      "SMA Reward: 10.055\n",
      "SMA Entropy: 0.9354924836754799\n",
      "SMA Loss: 0.013874934124760329\n",
      "SMA PG Loss: -0.015100411660969258\n",
      "SMA V Loss: 0.07666054081171751\n",
      "SMA Intrinsic Reward: 0.04493433561176061\n",
      "SMA ICM Loss: 0.4073778747022152\n",
      "Max reward: 32.0\n",
      "---------- 3675 / 4882 ----------\n",
      "Num Games: 12141\n",
      "Num Frames: 3762176\n",
      "FPS: 454\n",
      "ETA: 0:45:20\n",
      "SMA Length: 407.325\n",
      "SMA Reward: 10.005\n",
      "SMA Entropy: 0.941024440228939\n",
      "SMA Loss: 0.014140725992619991\n",
      "SMA PG Loss: -0.015108694969676435\n",
      "SMA V Loss: 0.07731933038681746\n",
      "SMA Intrinsic Reward: 0.044942913353443144\n",
      "SMA ICM Loss: 0.41039116904139517\n",
      "Max reward: 32.0\n",
      "---------- 3700 / 4882 ----------\n",
      "Num Games: 12210\n",
      "Num Frames: 3787776\n",
      "FPS: 454\n",
      "ETA: 0:44:24\n",
      "SMA Length: 403.585\n",
      "SMA Reward: 9.81\n",
      "SMA Entropy: 0.9477215138077736\n",
      "SMA Loss: 0.014425167464651167\n",
      "SMA PG Loss: -0.015135901311878116\n",
      "SMA V Loss: 0.07807656740769744\n",
      "SMA Intrinsic Reward: 0.04517159329727292\n",
      "SMA ICM Loss: 0.4141689340770245\n",
      "Max reward: 32.0\n",
      "---------- 3725 / 4882 ----------\n",
      "Num Games: 12273\n",
      "Num Frames: 3813376\n",
      "FPS: 454\n",
      "ETA: 0:43:28\n",
      "SMA Length: 397.76\n",
      "SMA Reward: 9.55\n",
      "SMA Entropy: 0.9558692353963852\n",
      "SMA Loss: 0.013759179287590087\n",
      "SMA PG Loss: -0.0157178011815995\n",
      "SMA V Loss: 0.0780713451653719\n",
      "SMA Intrinsic Reward: 0.04529082398861647\n",
      "SMA ICM Loss: 0.4202837619185448\n",
      "Max reward: 38.0\n",
      "---------- 3750 / 4882 ----------\n",
      "Num Games: 12338\n",
      "Num Frames: 3838976\n",
      "FPS: 454\n",
      "ETA: 0:42:31\n",
      "SMA Length: 398.935\n",
      "SMA Reward: 9.575\n",
      "SMA Entropy: 0.9585358953475952\n",
      "SMA Loss: 0.010597711973823608\n",
      "SMA PG Loss: -0.018314218728337436\n",
      "SMA V Loss: 0.0769945790246129\n",
      "SMA Intrinsic Reward: 0.04536535114049912\n",
      "SMA ICM Loss: 0.4217259158194065\n",
      "Max reward: 38.0\n",
      "---------- 3775 / 4882 ----------\n",
      "Num Games: 12403\n",
      "Num Frames: 3864576\n",
      "FPS: 454\n",
      "ETA: 0:41:35\n",
      "SMA Length: 414.72\n",
      "SMA Reward: 10.36\n",
      "SMA Entropy: 0.9559058690071106\n",
      "SMA Loss: 0.007826720243319868\n",
      "SMA PG Loss: -0.020527109378017484\n",
      "SMA V Loss: 0.07582577645778656\n",
      "SMA Intrinsic Reward: 0.045247585102915766\n",
      "SMA ICM Loss: 0.42133810982108116\n",
      "Max reward: 38.0\n",
      "---------- 3800 / 4882 ----------\n",
      "Num Games: 12471\n",
      "Num Frames: 3890176\n",
      "FPS: 455\n",
      "ETA: 0:40:38\n",
      "SMA Length: 397.9\n",
      "SMA Reward: 9.905\n",
      "SMA Entropy: 0.955248381793499\n",
      "SMA Loss: 0.00908297256566584\n",
      "SMA PG Loss: -0.019461507541127503\n",
      "SMA V Loss: 0.0761939276009798\n",
      "SMA Intrinsic Reward: 0.04504962159320712\n",
      "SMA ICM Loss: 0.4212488543987274\n",
      "Max reward: 38.0\n",
      "---------- 3825 / 4882 ----------\n",
      "Num Games: 12532\n",
      "Num Frames: 3915776\n",
      "FPS: 455\n",
      "ETA: 0:39:42\n",
      "SMA Length: 411.4\n",
      "SMA Reward: 10.33\n",
      "SMA Entropy: 0.9537737458944321\n",
      "SMA Loss: 0.010976111809723079\n",
      "SMA PG Loss: -0.018039899482391774\n",
      "SMA V Loss: 0.07710749732330441\n",
      "SMA Intrinsic Reward: 0.04487411132082343\n",
      "SMA ICM Loss: 0.41831685960292814\n",
      "Max reward: 38.0\n",
      "---------- 3850 / 4882 ----------\n",
      "Num Games: 12599\n",
      "Num Frames: 3941376\n",
      "FPS: 455\n",
      "ETA: 0:38:45\n",
      "SMA Length: 403.86\n",
      "SMA Reward: 9.84\n",
      "SMA Entropy: 0.9533811083436012\n",
      "SMA Loss: 0.009718621545471252\n",
      "SMA PG Loss: -0.01924637726508081\n",
      "SMA V Loss: 0.07699761955067515\n",
      "SMA Intrinsic Reward: 0.04464243331924081\n",
      "SMA ICM Loss: 0.41871571868658064\n",
      "Max reward: 38.0\n",
      "---------- 3875 / 4882 ----------\n",
      "Num Games: 12663\n",
      "Num Frames: 3966976\n",
      "FPS: 455\n",
      "ETA: 0:37:49\n",
      "SMA Length: 418.53\n",
      "SMA Reward: 10.39\n",
      "SMA Entropy: 0.9500784879922867\n",
      "SMA Loss: 0.011566954348236323\n",
      "SMA PG Loss: -0.017605663598515092\n",
      "SMA V Loss: 0.07734680529683828\n",
      "SMA Intrinsic Reward: 0.044335188400000336\n",
      "SMA ICM Loss: 0.41665317356586457\n",
      "Max reward: 38.0\n",
      "---------- 3900 / 4882 ----------\n",
      "Num Games: 12729\n",
      "Num Frames: 3992576\n",
      "FPS: 455\n",
      "ETA: 0:36:52\n",
      "SMA Length: 404.98\n",
      "SMA Reward: 10.035\n",
      "SMA Entropy: 0.9439413940906525\n",
      "SMA Loss: 0.010857986193150282\n",
      "SMA PG Loss: -0.018066085649188608\n",
      "SMA V Loss: 0.07672697128728032\n",
      "SMA Intrinsic Reward: 0.043859171848744154\n",
      "SMA ICM Loss: 0.4123092494904995\n",
      "Max reward: 38.0\n",
      "---------- 3925 / 4882 ----------\n",
      "Num Games: 12788\n",
      "Num Frames: 4018176\n",
      "FPS: 455\n",
      "ETA: 0:35:56\n",
      "SMA Length: 415.975\n",
      "SMA Reward: 10.64\n",
      "SMA Entropy: 0.9356351885199546\n",
      "SMA Loss: 0.012136703324504197\n",
      "SMA PG Loss: -0.016800927503500134\n",
      "SMA V Loss: 0.07658796522766352\n",
      "SMA Intrinsic Reward: 0.04337803391739726\n",
      "SMA ICM Loss: 0.40404758155345916\n",
      "Max reward: 38.0\n",
      "---------- 3950 / 4882 ----------\n",
      "Num Games: 12852\n",
      "Num Frames: 4043776\n",
      "FPS: 455\n",
      "ETA: 0:34:59\n",
      "SMA Length: 414.83\n",
      "SMA Reward: 10.64\n",
      "SMA Entropy: 0.934454872906208\n",
      "SMA Loss: 0.013063470306806267\n",
      "SMA PG Loss: -0.015726905949413776\n",
      "SMA V Loss: 0.07626984955742955\n",
      "SMA Intrinsic Reward: 0.04308466423302889\n",
      "SMA ICM Loss: 0.39990265160799027\n",
      "Max reward: 38.0\n",
      "---------- 3975 / 4882 ----------\n",
      "Num Games: 12919\n",
      "Num Frames: 4069376\n",
      "FPS: 455\n",
      "ETA: 0:34:03\n",
      "SMA Length: 413.56\n",
      "SMA Reward: 10.8\n",
      "SMA Entropy: 0.9340294501185418\n",
      "SMA Loss: 0.015056952177546918\n",
      "SMA PG Loss: -0.01379130727145821\n",
      "SMA V Loss: 0.07637710733339191\n",
      "SMA Intrinsic Reward: 0.04283631052821875\n",
      "SMA ICM Loss: 0.3970960094034672\n",
      "Max reward: 38.0\n",
      "---------- 4000 / 4882 ----------\n",
      "Num Games: 12985\n",
      "Num Frames: 4094976\n",
      "FPS: 455\n",
      "ETA: 0:33:06\n",
      "SMA Length: 403.5\n",
      "SMA Reward: 10.295\n",
      "SMA Entropy: 0.9349061572551727\n",
      "SMA Loss: 0.014201454375870526\n",
      "SMA PG Loss: -0.014581596781499683\n",
      "SMA V Loss: 0.07626422496512532\n",
      "SMA Intrinsic Reward: 0.04275834066793323\n",
      "SMA ICM Loss: 0.3944747380912304\n",
      "Max reward: 38.0\n",
      "---------- 4025 / 4882 ----------\n",
      "Num Games: 13045\n",
      "Num Frames: 4120576\n",
      "FPS: 455\n",
      "ETA: 0:32:10\n",
      "SMA Length: 411.475\n",
      "SMA Reward: 10.75\n",
      "SMA Entropy: 0.9358300083875656\n",
      "SMA Loss: 0.01360214877873659\n",
      "SMA PG Loss: -0.015330232323613018\n",
      "SMA V Loss: 0.07658136175945401\n",
      "SMA Intrinsic Reward: 0.04260768761858344\n",
      "SMA ICM Loss: 0.3962443447113037\n",
      "Max reward: 38.0\n",
      "---------- 4050 / 4882 ----------\n",
      "Num Games: 13113\n",
      "Num Frames: 4146176\n",
      "FPS: 455\n",
      "ETA: 0:31:14\n",
      "SMA Length: 406.895\n",
      "SMA Reward: 10.075\n",
      "SMA Entropy: 0.9392029383778572\n",
      "SMA Loss: 0.01297891141846776\n",
      "SMA PG Loss: -0.016582195938099176\n",
      "SMA V Loss: 0.07790627285838127\n",
      "SMA Intrinsic Reward: 0.0426541905850172\n",
      "SMA ICM Loss: 0.39723480239510534\n",
      "Max reward: 38.0\n",
      "---------- 4075 / 4882 ----------\n",
      "Num Games: 13173\n",
      "Num Frames: 4171776\n",
      "FPS: 455\n",
      "ETA: 0:30:17\n",
      "SMA Length: 422.345\n",
      "SMA Reward: 10.525\n",
      "SMA Entropy: 0.9428505197167396\n",
      "SMA Loss: 0.011278370223008096\n",
      "SMA PG Loss: -0.018201911121141164\n",
      "SMA V Loss: 0.07781757280230522\n",
      "SMA Intrinsic Reward: 0.042365583200007675\n",
      "SMA ICM Loss: 0.4000898836553097\n",
      "Max reward: 38.0\n",
      "---------- 4100 / 4882 ----------\n",
      "Num Games: 13240\n",
      "Num Frames: 4197376\n",
      "FPS: 455\n",
      "ETA: 0:29:21\n",
      "SMA Length: 406.745\n",
      "SMA Reward: 9.795\n",
      "SMA Entropy: 0.9484823447465897\n",
      "SMA Loss: 0.010475354711525142\n",
      "SMA PG Loss: -0.019272201408166437\n",
      "SMA V Loss: 0.07846475876867771\n",
      "SMA Intrinsic Reward: 0.042332295011729\n",
      "SMA ICM Loss: 0.4043166053295135\n",
      "Max reward: 38.0\n",
      "---------- 4125 / 4882 ----------\n",
      "Num Games: 13306\n",
      "Num Frames: 4222976\n",
      "FPS: 455\n",
      "ETA: 0:28:25\n",
      "SMA Length: 417.46\n",
      "SMA Reward: 10.13\n",
      "SMA Entropy: 0.9553595069050789\n",
      "SMA Loss: 0.008129008486866951\n",
      "SMA PG Loss: -0.020829275657888502\n",
      "SMA V Loss: 0.07702375791966914\n",
      "SMA Intrinsic Reward: 0.04230448961257935\n",
      "SMA ICM Loss: 0.4123505795001984\n",
      "Max reward: 38.0\n",
      "---------- 4150 / 4882 ----------\n",
      "Num Games: 13363\n",
      "Num Frames: 4248576\n",
      "FPS: 455\n",
      "ETA: 0:27:28\n",
      "SMA Length: 416.205\n",
      "SMA Reward: 9.9\n",
      "SMA Entropy: 0.9599978962540626\n",
      "SMA Loss: 0.010457364232279361\n",
      "SMA PG Loss: -0.01841562075307593\n",
      "SMA V Loss: 0.07694592764601112\n",
      "SMA Intrinsic Reward: 0.04219462232664228\n",
      "SMA ICM Loss: 0.4186232583224773\n",
      "Max reward: 38.0\n",
      "---------- 4175 / 4882 ----------\n",
      "Num Games: 13434\n",
      "Num Frames: 4274176\n",
      "FPS: 455\n",
      "ETA: 0:26:32\n",
      "SMA Length: 414.01\n",
      "SMA Reward: 9.695\n",
      "SMA Entropy: 0.9664349928498268\n",
      "SMA Loss: 0.0100067795580253\n",
      "SMA PG Loss: -0.019254613863304258\n",
      "SMA V Loss: 0.07785148652270436\n",
      "SMA Intrinsic Reward: 0.04215929977595806\n",
      "SMA ICM Loss: 0.42640635535120963\n",
      "Max reward: 38.0\n",
      "---------- 4200 / 4882 ----------\n",
      "Num Games: 13494\n",
      "Num Frames: 4299776\n",
      "FPS: 455\n",
      "ETA: 0:25:36\n",
      "SMA Length: 411.12\n",
      "SMA Reward: 9.885\n",
      "SMA Entropy: 0.9668597435951233\n",
      "SMA Loss: 0.009459165716543793\n",
      "SMA PG Loss: -0.02031227860134095\n",
      "SMA V Loss: 0.07888008322566747\n",
      "SMA Intrinsic Reward: 0.04192329363897443\n",
      "SMA ICM Loss: 0.42897128134965895\n",
      "Max reward: 38.0\n",
      "---------- 4225 / 4882 ----------\n",
      "Num Games: 13558\n",
      "Num Frames: 4325376\n",
      "FPS: 455\n",
      "ETA: 0:24:39\n",
      "SMA Length: 409.415\n",
      "SMA Reward: 9.805\n",
      "SMA Entropy: 0.9696649807691574\n",
      "SMA Loss: 0.008869114313274622\n",
      "SMA PG Loss: -0.020539290781598538\n",
      "SMA V Loss: 0.07821010956540704\n",
      "SMA Intrinsic Reward: 0.041829994041472675\n",
      "SMA ICM Loss: 0.4331194433569908\n",
      "Max reward: 38.0\n",
      "---------- 4250 / 4882 ----------\n",
      "Num Games: 13624\n",
      "Num Frames: 4350976\n",
      "FPS: 455\n",
      "ETA: 0:23:43\n",
      "SMA Length: 411.94\n",
      "SMA Reward: 10.03\n",
      "SMA Entropy: 0.9667872044444085\n",
      "SMA Loss: 0.009075312381610275\n",
      "SMA PG Loss: -0.020066881685052065\n",
      "SMA V Loss: 0.07762013202533126\n",
      "SMA Intrinsic Reward: 0.04148456243798137\n",
      "SMA ICM Loss: 0.43291104078292847\n",
      "Max reward: 38.0\n",
      "---------- 4275 / 4882 ----------\n",
      "Num Games: 13687\n",
      "Num Frames: 4376576\n",
      "FPS: 455\n",
      "ETA: 0:22:47\n",
      "SMA Length: 422.83\n",
      "SMA Reward: 10.5\n",
      "SMA Entropy: 0.9634814050793647\n",
      "SMA Loss: 0.009180514980107546\n",
      "SMA PG Loss: -0.01986742337467149\n",
      "SMA V Loss: 0.07736550429835916\n",
      "SMA Intrinsic Reward: 0.04131982278078795\n",
      "SMA ICM Loss: 0.4303896179795265\n",
      "Max reward: 38.0\n",
      "---------- 4300 / 4882 ----------\n",
      "Num Games: 13745\n",
      "Num Frames: 4402176\n",
      "FPS: 455\n",
      "ETA: 0:21:51\n",
      "SMA Length: 426.595\n",
      "SMA Reward: 10.785\n",
      "SMA Entropy: 0.9652276065945625\n",
      "SMA Loss: 0.010438052173703909\n",
      "SMA PG Loss: -0.018692664655391128\n",
      "SMA V Loss: 0.0775659853965044\n",
      "SMA Intrinsic Reward: 0.041216698624193665\n",
      "SMA ICM Loss: 0.4322332201898098\n",
      "Max reward: 38.0\n",
      "---------- 4325 / 4882 ----------\n",
      "Num Games: 13810\n",
      "Num Frames: 4427776\n",
      "FPS: 456\n",
      "ETA: 0:20:54\n",
      "SMA Length: 430.325\n",
      "SMA Reward: 10.685\n",
      "SMA Entropy: 0.96354911506176\n",
      "SMA Loss: 0.013750702333636582\n",
      "SMA PG Loss: -0.01662121820030734\n",
      "SMA V Loss: 0.0800148231163621\n",
      "SMA Intrinsic Reward: 0.041242149174213406\n",
      "SMA ICM Loss: 0.4269767309725285\n",
      "Max reward: 38.0\n",
      "---------- 4350 / 4882 ----------\n",
      "Num Games: 13881\n",
      "Num Frames: 4453376\n",
      "FPS: 456\n",
      "ETA: 0:19:58\n",
      "SMA Length: 411.83\n",
      "SMA Reward: 9.865\n",
      "SMA Entropy: 0.9631387650966644\n",
      "SMA Loss: 0.011697362754493951\n",
      "SMA PG Loss: -0.01916171213844791\n",
      "SMA V Loss: 0.0809809247404337\n",
      "SMA Intrinsic Reward: 0.041254736352711915\n",
      "SMA ICM Loss: 0.42302501559257505\n",
      "Max reward: 38.0\n",
      "---------- 4375 / 4882 ----------\n",
      "Num Games: 13939\n",
      "Num Frames: 4478976\n",
      "FPS: 456\n",
      "ETA: 0:19:02\n",
      "SMA Length: 417.035\n",
      "SMA Reward: 9.96\n",
      "SMA Entropy: 0.9621774294972419\n",
      "SMA Loss: 0.010595365827903151\n",
      "SMA PG Loss: -0.01980434444732964\n",
      "SMA V Loss: 0.08004296874627471\n",
      "SMA Intrinsic Reward: 0.04111184652894735\n",
      "SMA ICM Loss: 0.42029925286769865\n",
      "Max reward: 38.0\n",
      "---------- 4400 / 4882 ----------\n",
      "Num Games: 14011\n",
      "Num Frames: 4504576\n",
      "FPS: 456\n",
      "ETA: 0:18:05\n",
      "SMA Length: 395.405\n",
      "SMA Reward: 9.58\n",
      "SMA Entropy: 0.9633072823286056\n",
      "SMA Loss: 0.010786541355773806\n",
      "SMA PG Loss: -0.0191960083367303\n",
      "SMA V Loss: 0.0792312447167933\n",
      "SMA Intrinsic Reward: 0.04109704015776515\n",
      "SMA ICM Loss: 0.4180275771021843\n",
      "Max reward: 38.0\n",
      "---------- 4425 / 4882 ----------\n",
      "Num Games: 14069\n",
      "Num Frames: 4530176\n",
      "FPS: 456\n",
      "ETA: 0:17:09\n",
      "SMA Length: 414.03\n",
      "SMA Reward: 10.29\n",
      "SMA Entropy: 0.9610891243815423\n",
      "SMA Loss: 0.012909817616455257\n",
      "SMA PG Loss: -0.017335387831553816\n",
      "SMA V Loss: 0.07971219312399626\n",
      "SMA Intrinsic Reward: 0.04083257494494319\n",
      "SMA ICM Loss: 0.41363041356205943\n",
      "Max reward: 38.0\n",
      "---------- 4450 / 4882 ----------\n",
      "Num Games: 14137\n",
      "Num Frames: 4555776\n",
      "FPS: 456\n",
      "ETA: 0:16:13\n",
      "SMA Length: 405.055\n",
      "SMA Reward: 10.335\n",
      "SMA Entropy: 0.9607233792543411\n",
      "SMA Loss: 0.012329834969714284\n",
      "SMA PG Loss: -0.017678834197577088\n",
      "SMA V Loss: 0.07923180563375354\n",
      "SMA Intrinsic Reward: 0.04074924025684595\n",
      "SMA ICM Loss: 0.4126267372071743\n",
      "Max reward: 38.0\n",
      "---------- 4475 / 4882 ----------\n",
      "Num Games: 14201\n",
      "Num Frames: 4581376\n",
      "FPS: 456\n",
      "ETA: 0:15:17\n",
      "SMA Length: 413.48\n",
      "SMA Reward: 10.275\n",
      "SMA Entropy: 0.9669019716978073\n",
      "SMA Loss: 0.011755285291001201\n",
      "SMA PG Loss: -0.017803215628955513\n",
      "SMA V Loss: 0.0784550410322845\n",
      "SMA Intrinsic Reward: 0.04076340917497873\n",
      "SMA ICM Loss: 0.4167865043878555\n",
      "Max reward: 38.0\n",
      "---------- 4500 / 4882 ----------\n",
      "Num Games: 14263\n",
      "Num Frames: 4606976\n",
      "FPS: 456\n",
      "ETA: 0:14:21\n",
      "SMA Length: 408.32\n",
      "SMA Reward: 10.185\n",
      "SMA Entropy: 0.9641946718096733\n",
      "SMA Loss: 0.011596395689994097\n",
      "SMA PG Loss: -0.01778079608688131\n",
      "SMA V Loss: 0.07803827669471503\n",
      "SMA Intrinsic Reward: 0.04053336914628744\n",
      "SMA ICM Loss: 0.4137696167826653\n",
      "Max reward: 38.0\n",
      "---------- 4525 / 4882 ----------\n",
      "Num Games: 14331\n",
      "Num Frames: 4632576\n",
      "FPS: 456\n",
      "ETA: 0:13:25\n",
      "SMA Length: 404.12\n",
      "SMA Reward: 9.715\n",
      "SMA Entropy: 0.9656142869591713\n",
      "SMA Loss: 0.010392965315841139\n",
      "SMA PG Loss: -0.0184796596202068\n",
      "SMA V Loss: 0.07705753514543176\n",
      "SMA Intrinsic Reward: 0.0403265798278153\n",
      "SMA ICM Loss: 0.4159882289171219\n",
      "Max reward: 38.0\n",
      "---------- 4550 / 4882 ----------\n",
      "Num Games: 14393\n",
      "Num Frames: 4658176\n",
      "FPS: 456\n",
      "ETA: 0:12:29\n",
      "SMA Length: 407.595\n",
      "SMA Reward: 9.85\n",
      "SMA Entropy: 0.9668554642796516\n",
      "SMA Loss: 0.011945974766276776\n",
      "SMA PG Loss: -0.016585231779608876\n",
      "SMA V Loss: 0.07639952186495065\n",
      "SMA Intrinsic Reward: 0.04010970950126648\n",
      "SMA ICM Loss: 0.4180807754397392\n",
      "Max reward: 38.0\n",
      "---------- 4575 / 4882 ----------\n",
      "Num Games: 14453\n",
      "Num Frames: 4683776\n",
      "FPS: 456\n",
      "ETA: 0:11:32\n",
      "SMA Length: 423.485\n",
      "SMA Reward: 10.43\n",
      "SMA Entropy: 0.9653607153892517\n",
      "SMA Loss: 0.013540055197663605\n",
      "SMA PG Loss: -0.015397778756450861\n",
      "SMA V Loss: 0.07718288162723183\n",
      "SMA Intrinsic Reward: 0.03991841856390238\n",
      "SMA ICM Loss: 0.41706090614199637\n",
      "Max reward: 38.0\n",
      "---------- 4600 / 4882 ----------\n",
      "Num Games: 14522\n",
      "Num Frames: 4709376\n",
      "FPS: 456\n",
      "ETA: 0:10:36\n",
      "SMA Length: 415.83\n",
      "SMA Reward: 10.315\n",
      "SMA Entropy: 0.9648263525962829\n",
      "SMA Loss: 0.013978065699338913\n",
      "SMA PG Loss: -0.015052894332911819\n",
      "SMA V Loss: 0.07735844660550356\n",
      "SMA Intrinsic Reward: 0.03971680354326963\n",
      "SMA ICM Loss: 0.41745899602770803\n",
      "Max reward: 38.0\n",
      "---------- 4625 / 4882 ----------\n",
      "Num Games: 14585\n",
      "Num Frames: 4734976\n",
      "FPS: 456\n",
      "ETA: 0:09:40\n",
      "SMA Length: 417.015\n",
      "SMA Reward: 10.605\n",
      "SMA Entropy: 0.9645537278056144\n",
      "SMA Loss: 0.010950173856690526\n",
      "SMA PG Loss: -0.017427674133796246\n",
      "SMA V Loss: 0.07604676991701126\n",
      "SMA Intrinsic Reward: 0.03960611186921596\n",
      "SMA ICM Loss: 0.4209844517707825\n",
      "Max reward: 38.0\n",
      "---------- 4650 / 4882 ----------\n",
      "Num Games: 14645\n",
      "Num Frames: 4760576\n",
      "FPS: 456\n",
      "ETA: 0:08:44\n",
      "SMA Length: 413.16\n",
      "SMA Reward: 10.74\n",
      "SMA Entropy: 0.9634169089794159\n",
      "SMA Loss: 0.012069772337563336\n",
      "SMA PG Loss: -0.01621201026486233\n",
      "SMA V Loss: 0.07583190280944109\n",
      "SMA Intrinsic Reward: 0.03937260862439871\n",
      "SMA ICM Loss: 0.42122133523225785\n",
      "Max reward: 38.0\n",
      "---------- 4675 / 4882 ----------\n",
      "Num Games: 14715\n",
      "Num Frames: 4786176\n",
      "FPS: 456\n",
      "ETA: 0:07:48\n",
      "SMA Length: 414.075\n",
      "SMA Reward: 10.505\n",
      "SMA Entropy: 0.963701854646206\n",
      "SMA Loss: 0.010533005497418344\n",
      "SMA PG Loss: -0.017948784122709185\n",
      "SMA V Loss: 0.0762376157939434\n",
      "SMA Intrinsic Reward: 0.03923339501023292\n",
      "SMA ICM Loss: 0.42168558940291406\n",
      "Max reward: 38.0\n",
      "---------- 4700 / 4882 ----------\n",
      "Num Games: 14785\n",
      "Num Frames: 4811776\n",
      "FPS: 456\n",
      "ETA: 0:06:52\n",
      "SMA Length: 398.51\n",
      "SMA Reward: 9.915\n",
      "SMA Entropy: 0.9629580336809158\n",
      "SMA Loss: 0.010293927155435085\n",
      "SMA PG Loss: -0.017834160716738552\n",
      "SMA V Loss: 0.07551533591002225\n",
      "SMA Intrinsic Reward: 0.03907302925363183\n",
      "SMA ICM Loss: 0.4207596670091152\n",
      "Max reward: 38.0\n",
      "---------- 4725 / 4882 ----------\n",
      "Num Games: 14857\n",
      "Num Frames: 4837376\n",
      "FPS: 456\n",
      "ETA: 0:05:56\n",
      "SMA Length: 375.415\n",
      "SMA Reward: 8.76\n",
      "SMA Entropy: 0.9626248574256897\n",
      "SMA Loss: 0.007600194201804697\n",
      "SMA PG Loss: -0.020526703430805357\n",
      "SMA V Loss: 0.07550629196688532\n",
      "SMA Intrinsic Reward: 0.03881509203463793\n",
      "SMA ICM Loss: 0.41997476637363435\n",
      "Max reward: 38.0\n",
      "---------- 4750 / 4882 ----------\n",
      "Num Games: 14926\n",
      "Num Frames: 4862976\n",
      "FPS: 456\n",
      "ETA: 0:05:00\n",
      "SMA Length: 373.01\n",
      "SMA Reward: 8.955\n",
      "SMA Entropy: 0.9608765843510628\n",
      "SMA Loss: 0.008512244164012372\n",
      "SMA PG Loss: -0.019686393623705955\n",
      "SMA V Loss: 0.0756148070283234\n",
      "SMA Intrinsic Reward: 0.03858665332198143\n",
      "SMA ICM Loss: 0.419524537473917\n",
      "Max reward: 38.0\n",
      "---------- 4775 / 4882 ----------\n",
      "Num Games: 14987\n",
      "Num Frames: 4888576\n",
      "FPS: 456\n",
      "ETA: 0:04:04\n",
      "SMA Length: 390.67\n",
      "SMA Reward: 9.37\n",
      "SMA Entropy: 0.965091823041439\n",
      "SMA Loss: 0.0077183752274140715\n",
      "SMA PG Loss: -0.020072797674220055\n",
      "SMA V Loss: 0.07488418210297823\n",
      "SMA Intrinsic Reward: 0.038593607973307374\n",
      "SMA ICM Loss: 0.42281885161995886\n",
      "Max reward: 38.0\n",
      "---------- 4800 / 4882 ----------\n",
      "Num Games: 15051\n",
      "Num Frames: 4914176\n",
      "FPS: 456\n",
      "ETA: 0:03:07\n",
      "SMA Length: 408.52\n",
      "SMA Reward: 10.15\n",
      "SMA Entropy: 0.9657265147566796\n",
      "SMA Loss: 0.006737525607459247\n",
      "SMA PG Loss: -0.020635774496477098\n",
      "SMA V Loss: 0.07406113022938371\n",
      "SMA Intrinsic Reward: 0.03835362382233143\n",
      "SMA ICM Loss: 0.42578014701604844\n",
      "Max reward: 38.0\n",
      "---------- 4825 / 4882 ----------\n",
      "Num Games: 15115\n",
      "Num Frames: 4939776\n",
      "FPS: 456\n",
      "ETA: 0:02:11\n",
      "SMA Length: 413.335\n",
      "SMA Reward: 10.25\n",
      "SMA Entropy: 0.9652604347467423\n",
      "SMA Loss: 0.006410022904165089\n",
      "SMA PG Loss: -0.021440715382341297\n",
      "SMA V Loss: 0.07500668503344059\n",
      "SMA Intrinsic Reward: 0.03822741873562336\n",
      "SMA ICM Loss: 0.4214007322490215\n",
      "Max reward: 38.0\n",
      "---------- 4850 / 4882 ----------\n",
      "Num Games: 15181\n",
      "Num Frames: 4965376\n",
      "FPS: 456\n",
      "ETA: 0:01:15\n",
      "SMA Length: 405.795\n",
      "SMA Reward: 9.905\n",
      "SMA Entropy: 0.9695520862936974\n",
      "SMA Loss: 0.006656954386271536\n",
      "SMA PG Loss: -0.021226846231147647\n",
      "SMA V Loss: 0.07515864266082645\n",
      "SMA Intrinsic Reward: 0.03821882164105773\n",
      "SMA ICM Loss: 0.4241277442872524\n",
      "Max reward: 38.0\n",
      "---------- 4875 / 4882 ----------\n",
      "Num Games: 15241\n",
      "Num Frames: 4990976\n",
      "FPS: 456\n",
      "ETA: 0:00:19\n",
      "SMA Length: 412.075\n",
      "SMA Reward: 10.25\n",
      "SMA Entropy: 0.9669061324000359\n",
      "SMA Loss: 0.008711105617694557\n",
      "SMA PG Loss: -0.019090141537599265\n",
      "SMA V Loss: 0.07494061654433608\n",
      "SMA Intrinsic Reward: 0.037988510299474004\n",
      "SMA ICM Loss: 0.4230382071435452\n",
      "Max reward: 38.0\n"
     ]
    }
   ],
   "source": [
    "rollouts = rollout_generator(env, ac)\n",
    "scheduler = LambdaLR(ac_optimizer, lambda i: 1 - i / TOTAL_UPDATES)\n",
    "\n",
    "for i_update in range(logger.n_update, TOTAL_UPDATES):\n",
    "\n",
    "    mb, ep = next(rollouts)\n",
    "\n",
    "    # policy gradient + entropy\n",
    "    logits, val = ac(mb['obs'])\n",
    "    dist = Categorical(logits=logits)\n",
    "    ent = dist.entropy().mean()\n",
    "    logp = dist.log_prob(mb['act'])\n",
    "    \n",
    "    # intrinsic reward (not baselined)\n",
    "    inverse_loss, forward_mse = icm(mb['obs'], mb['nobs'], mb['act'])\n",
    "    int_rwd = forward_mse.detach()\n",
    "\n",
    "    # normalized extrinsic + intrinsic advantage\n",
    "    adv = mb['gae']*0.99 + int_rwd*0.01\n",
    "    adv = (adv - adv.mean()) / (adv.std() + 1e-8)\n",
    "\n",
    "    # calculate losses (soft ac with entropy)\n",
    "    vloss = (val.view(-1) - mb['rtn']).pow(2).mean()\n",
    "    pgloss = -(adv * logp).mean()\n",
    "    loss = pgloss + 0.5*vloss - 0.01*ent\n",
    "    \n",
    "    # step policy\n",
    "    ac_optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(ac.parameters(), 0.5)\n",
    "    ac_optimizer.step()\n",
    "    scheduler.step(i_update)\n",
    "    \n",
    "    # step icm\n",
    "    icm_loss = 0.8*inverse_loss.mean() + 0.2*forward_mse.mean()\n",
    "    icm_optimizer.zero_grad()\n",
    "    icm_loss.backward()\n",
    "    nn.utils.clip_grad_norm_(icm.parameters(), 0.5)\n",
    "    icm_optimizer.step()\n",
    "    \n",
    "    # log training stats\n",
    "    logger.record(ep, loss.item(), pgloss.item(), vloss.item(), ent.item(),\n",
    "                  int_rwd.mean().item(), icm_loss.item())\n",
    "    # make a checkpoint every 1m frames\n",
    "    if logger.n_frames - logger.last_checkpoint > 1e6:\n",
    "        save_checkpoint(logger.n_frames)\n",
    "        logger.last_checkpoint = logger.n_frames\n",
    "    \n",
    "#     if i_update % 25 == 0:\n",
    "#         print('SOFTMAX: ', dist.probs)\n",
    "        \n",
    "save_checkpoint('FINAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WySNQ9nExig2"
   },
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50KIcAvCz58G"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sWvCD53L3_j4"
   },
   "outputs": [],
   "source": [
    "def plot_log(log, ylabel):\n",
    "    # compute rolling avg and std\n",
    "    df = pd.DataFrame(log, columns =['Frames', 'Iters', ylabel])\n",
    "    sma_y = df[ylabel].rolling(500).mean()\n",
    "    std_y = df[ylabel].rolling(500).std()\n",
    "    \n",
    "    # plot with seaborn\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax.set_xlabel('Frames')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    clrs = sns.color_palette(\"husl\", 8)\n",
    "\n",
    "    # fill standard deviation\n",
    "    ax.plot(df['Frames'], sma_y, label=ylabel, c=clrs[0])\n",
    "    ax.fill_between(df['Frames'], sma_y-std_y,  sma_y+std_y, \n",
    "                    alpha=0.3, facecolor=clrs[0]) \n",
    "    ax.legend(loc='upper left')\n",
    "    plt.savefig(SAVE_PATH+ENV_NAME+'.'+ylabel+'.plt.png', \n",
    "                dpi=300, pad_inches=0)\n",
    "    plt.show()\n",
    "\n",
    "plot_log(logger.log['ep_r'], 'Reward')\n",
    "plot_log(logger.log['ep_l'], 'Length')\n",
    "plot_log(logger.log['loss'], 'Loss')\n",
    "plot_log(logger.log['ent'], 'Entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EtbghdlmxihB"
   },
   "outputs": [],
   "source": [
    "fig_all, ax_all = plt.subplots(2,4, figsize=(8,8))\n",
    "\n",
    "## REWARD \n",
    "df = pd.DataFrame(logger.log['ep_r'], columns =['Frames', 'Iters', 'rwd'])\n",
    "sma_y = df['rwd'].rolling(500).mean()\n",
    "std_y = df['rwd'].rolling(500).std()\n",
    "\n",
    "ax_all[0][0].set_ylabel('Reward')\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "\n",
    "# fill standard deviation\n",
    "ax_all[0][0].plot(df['Frames'], sma_y, label='Episode Reward', c=clrs[0])\n",
    "ax_all[0][0].fill_between(df['Frames'], sma_y-std_y,  sma_y+std_y, \n",
    "                alpha=0.3, facecolor=clrs[0])\n",
    "\n",
    "# make x axis nice\n",
    "ax_all[0][0].set_xticklabels('')\n",
    "\n",
    "\n",
    "## LENGTH \n",
    "df = pd.DataFrame(logger.log['ep_l'], columns =['Frames', 'Iters', 'Len'])\n",
    "sma_y = df['Len'].rolling(500).mean()\n",
    "std_y = df['Len'].rolling(500).std()\n",
    "\n",
    "ax_all[0][1].set_ylabel('Length')\n",
    "ax_all[0][1].yaxis.tick_right()\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "\n",
    "# fill standard deviation\n",
    "ax_all[0][1].plot(df['Frames'], sma_y, label='Episode Length', c=clrs[0])\n",
    "ax_all[0][1].fill_between(df['Frames'], sma_y-std_y,  sma_y+std_y, \n",
    "                alpha=0.3, facecolor=clrs[0])\n",
    "\n",
    "# make x axis nice\n",
    "ax_all[0][1].set_xticklabels('')\n",
    "\n",
    "\n",
    "## ENTROPY \n",
    "df = pd.DataFrame(logger.log['ent'], columns =['Frames', 'Iters', 'ent'])\n",
    "sma_y = df['ent'].rolling(500).mean()\n",
    "std_y = df['ent'].rolling(500).std()\n",
    "\n",
    "ax_all[1][0].set_xlabel('Frames')\n",
    "ax_all[1][0].set_ylabel('Entropy')\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "\n",
    "# fill standard deviation\n",
    "ax_all[1][0].plot(df['Frames'], sma_y, label='Entropy', c=clrs[0])\n",
    "ax_all[1][0].fill_between(df['Frames'], sma_y-std_y,  sma_y+std_y, \n",
    "                alpha=0.3, facecolor=clrs[0])\n",
    "\n",
    "# make x axis nice\n",
    "xlabels = [f'{int(x)}M' for x in ax_all[1][0].get_xticks()/1e6]\n",
    "ax_all[1][0].set_xticklabels(xlabels)\n",
    "\n",
    "\n",
    "## LOSS \n",
    "df = pd.DataFrame(logger.log['loss'], columns =['Frames', 'Iters', 'Loss'])\n",
    "sma_y = df['Loss'].rolling(500).mean()\n",
    "std_y = df['Loss'].rolling(500).std()\n",
    "\n",
    "ax_all[1][1].set_xlabel('Frames')\n",
    "ax_all[1][1].set_ylabel('Loss')\n",
    "ax_all[1][1].yaxis.tick_right()\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "\n",
    "# fill standard deviation\n",
    "ax_all[1][1].plot(df['Frames'], sma_y, label='Loss', c=clrs[0])\n",
    "ax_all[1][1].fill_between(df['Frames'], sma_y-std_y,  sma_y+std_y, \n",
    "                alpha=0.3, facecolor=clrs[0])\n",
    "\n",
    "# make x axis nice\n",
    "xlabels = [f'{int(x)}M' for x in ax_all[1][1].get_xticks()/1e6]\n",
    "ax_all[1][1].set_xticklabels(xlabels)\n",
    "\n",
    "\n",
    "## V LOSS \n",
    "df = pd.DataFrame(logger.log['vloss'], columns =['Frames', 'Iters', 'Loss'])\n",
    "sma_y = df['Loss'].rolling(500).mean()\n",
    "std_y = df['Loss'].rolling(500).std()\n",
    "\n",
    "ax_all[1][2].set_xlabel('Frames')\n",
    "ax_all[1][2].set_ylabel('Value Loss')\n",
    "ax_all[1][2].yaxis.tick_right()\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "\n",
    "# fill standard deviation\n",
    "ax_all[1][2].plot(df['Frames'], sma_y, label='V Loss', c=clrs[0])\n",
    "ax_all[1][2].fill_between(df['Frames'], sma_y-std_y,  sma_y+std_y, \n",
    "                alpha=0.3, facecolor=clrs[0])\n",
    "\n",
    "# make x axis nice\n",
    "xlabels = [f'{int(x)}M' for x in ax_all[1][2].get_xticks()/1e6]\n",
    "ax_all[1][2].set_xticklabels(xlabels)\n",
    "\n",
    "\n",
    "## INTRINSIC REWARD\n",
    "df = pd.DataFrame(logger.log['int'], columns =['Frames', 'Iters', 'Int'])\n",
    "sma_y = df['Int'].rolling(500).mean()\n",
    "std_y = df['Int'].rolling(500).std()\n",
    "\n",
    "ax_all[0][2].set_xlabel('Frames')\n",
    "ax_all[0][2].set_ylabel('Intrinsic Reward')\n",
    "ax_all[0][2].yaxis.tick_right()\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "\n",
    "# fill standard deviation\n",
    "ax_all[0][2].plot(df['Frames'], sma_y, label='Intrinsic Reward', c=clrs[0])\n",
    "ax_all[0][2].fill_between(df['Frames'], sma_y-std_y,  sma_y+std_y, \n",
    "                alpha=0.3, facecolor=clrs[0])\n",
    "\n",
    "# make x axis nice\n",
    "xlabels = [f'{int(x)}M' for x in ax_all[0][2].get_xticks()/1e6]\n",
    "ax_all[0][2].set_xticklabels(xlabels)\n",
    "\n",
    "\n",
    "### ICM LOSS\n",
    "\n",
    "df = pd.DataFrame(logger.log['icm'], columns =['Frames', 'Iters', 'Int'])\n",
    "sma_y = df['Int'].rolling(500).mean()\n",
    "std_y = df['Int'].rolling(500).std()\n",
    "\n",
    "ax_all[0][3].set_xlabel('Frames')\n",
    "ax_all[0][3].set_ylabel('ICM Loss')\n",
    "ax_all[0][3].yaxis.tick_right()\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "\n",
    "# fill standard deviation\n",
    "ax_all[0][3].plot(df['Frames'], sma_y, label='ICM Loss', c=clrs[0])\n",
    "ax_all[0][3].fill_between(df['Frames'], sma_y-std_y,  sma_y+std_y, \n",
    "                alpha=0.3, facecolor=clrs[0])\n",
    "\n",
    "# make x axis nice\n",
    "xlabels = [f'{int(x)}M' for x in ax_all[0][3].get_xticks()/1e6]\n",
    "ax_all[0][3].set_xticklabels(xlabels)\n",
    "\n",
    "\n",
    "### PG Loss\n",
    "\n",
    "df = pd.DataFrame(logger.log['pgloss'], columns =['Frames', 'Iters', 'PG'])\n",
    "sma_y = df['PG'].rolling(500).mean()\n",
    "std_y = df['PG'].rolling(500).std()\n",
    "\n",
    "ax_all[0][3].set_xlabel('Frames')\n",
    "ax_all[0][3].set_ylabel('PG Loss')\n",
    "ax_all[0][3].yaxis.tick_right()\n",
    "clrs = sns.color_palette(\"husl\", 8)\n",
    "\n",
    "# fill standard deviation\n",
    "ax_all[0][3].plot(df['Frames'], sma_y, label='PG Loss', c=clrs[0])\n",
    "ax_all[0][3].fill_between(df['Frames'], sma_y-std_y,  sma_y+std_y, \n",
    "                alpha=0.3, facecolor=clrs[0])\n",
    "\n",
    "# make x axis nice\n",
    "xlabels = [f'{int(x)}M' for x in ax_all[0][3].get_xticks()/1e6]\n",
    "ax_all[0][3].set_xticklabels(xlabels)\n",
    "\n",
    "\n",
    "### Plot & save\n",
    "\n",
    "plt.savefig(SAVE_PATH+ENV_NAME+'_plot_thesis.png', \n",
    "            dpi=300, pad_inches=0, bbox_inches = 'tight')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BAbfQ3HkxxJP"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(logger.log, open(SAVE_PATH+'FINAL.'+ENV_NAME+'.log', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFNuCO89xxbE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ICM_Atari_Breakout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
